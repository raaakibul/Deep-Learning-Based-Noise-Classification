{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238c5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's read a sample audio using librosa\n",
    "import librosa\n",
    "audio_file_path='UrbanSound8K/100263-2-0-3.wav'\n",
    "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993af439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00327535  0.00470622  0.00359118 ... -0.00371737 -0.00352591\n",
      " -0.0035292 ]\n"
     ]
    }
   ],
   "source": [
    "print(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b17a9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ba6cc99e80>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Lets plot the librosa audio data\n",
    "import matplotlib.pyplot as plt\n",
    "# Original audio with 1 channel \n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab783ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets read with scipy\n",
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio = wav.read(audio_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce731fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets read with scipy\n",
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio = wav.read(audio_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c3f99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 194,  100],\n",
       "       [ 179,  113],\n",
       "       [ 160,  124],\n",
       "       ...,\n",
       "       [-143,  -87],\n",
       "       [-134,  -91],\n",
       "       [-110,  -98]], dtype=int16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ccc9122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ba6cd47ca0>,\n",
       " <matplotlib.lines.Line2D at 0x2ba6cd47d00>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Original audio with 2 channels \n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(wave_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2037a0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 173)\n"
     ]
    }
   ],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14a60d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.76983704e+02, -4.54081116e+02, -4.52210968e+02, ...,\n",
       "        -4.80044495e+02, -4.75459564e+02, -4.91704163e+02],\n",
       "       [ 1.18308380e+02,  1.15959885e+02,  1.15713654e+02, ...,\n",
       "         1.15763275e+02,  1.13561340e+02,  1.04188065e+02],\n",
       "       [-2.13244038e+01, -2.91875744e+01, -3.47086411e+01, ...,\n",
       "        -1.28605824e+01, -1.20376644e+01, -5.69748783e+00],\n",
       "       ...,\n",
       "       [-2.17649651e+00, -2.13805175e+00, -4.00922489e+00, ...,\n",
       "         3.15193772e-01,  3.51474214e+00,  7.31593609e+00],\n",
       "       [-1.06117499e+00, -1.59224272e+00, -1.59618878e+00, ...,\n",
       "        -5.39944112e-01,  9.07173634e-01,  2.92428446e+00],\n",
       "       [-6.15000486e-01,  1.59921479e+00,  7.02612257e+00, ...,\n",
       "        -2.00688696e+00, -5.01437950e+00, -3.42770696e+00]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14910cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100263-2-0-143.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100263-2-0-161.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100263-2-0-3.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100263-2-0-36.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100648-1-0-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>4.823402</td>\n",
       "      <td>5.471927</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID      start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032   0.000000   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263  58.500000  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263  60.500000  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263  63.000000  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263  68.500000  72.500000         1     5        2   \n",
       "5  100263-2-0-143.wav  100263  71.500000  75.500000         1     5        2   \n",
       "6  100263-2-0-161.wav  100263  80.500000  84.500000         1     5        2   \n",
       "7    100263-2-0-3.wav  100263   1.500000   5.500000         1     5        2   \n",
       "8   100263-2-0-36.wav  100263  18.000000  22.000000         1     5        2   \n",
       "9    100648-1-0-0.wav  100648   4.823402   5.471927         2    10        1   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  \n",
       "5  children_playing  \n",
       "6  children_playing  \n",
       "7  children_playing  \n",
       "8  children_playing  \n",
       "9          car_horn  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Extracting MFCC's For every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path='UrbanSound8K/audio/'\n",
    "metadata=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8437cf31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>jackhammer</th>\n",
       "      <th>dog_bark</th>\n",
       "      <th>children_playing</th>\n",
       "      <th>street_music</th>\n",
       "      <th>air_conditioner</th>\n",
       "      <th>drilling</th>\n",
       "      <th>engine_idling</th>\n",
       "      <th>siren</th>\n",
       "      <th>car_horn</th>\n",
       "      <th>gun_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fold1</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fold2</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fold3</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>119</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fold4</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>166</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fold5</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>98</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fold6</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fold7</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>106</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fold8</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fold9</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fold10</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  jackhammer  dog_bark  children_playing  street_music  \\\n",
       "0   fold1         120       100               100           100   \n",
       "1   fold2         120       100               100           100   \n",
       "2   fold3         120       100               100           100   \n",
       "3   fold4         120       100               100           100   \n",
       "4   fold5         120       100               100           100   \n",
       "5   fold6          68       100               100           100   \n",
       "6   fold7          76       100               100           100   \n",
       "7   fold8          78       100               100           100   \n",
       "8   fold9          82       100               100           100   \n",
       "9  fold10          96       100               100           100   \n",
       "\n",
       "   air_conditioner  drilling  engine_idling  siren  car_horn  gun_shot  \n",
       "0              100       100             96     86        36        35  \n",
       "1              100       100            100     91        42        35  \n",
       "2              100       100            107    119        43        36  \n",
       "3              100       100            107    166        59        38  \n",
       "4              100       100            107     71        98        40  \n",
       "5              100       100            107     74        28        46  \n",
       "6              100       100            106     77        28        51  \n",
       "7              100       100             88     80        30        30  \n",
       "8              100       100             89     82        32        31  \n",
       "9              100       100             93     83        33        32  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended = []\n",
    "for i in range(1,11):\n",
    "    appended.append(metadata[metadata.fold == i]['class'].value_counts())\n",
    "    \n",
    "class_distribution = pd.DataFrame(appended)\n",
    "class_distribution = class_distribution.reset_index()\n",
    "class_distribution['index'] = [\"fold\"+str(x) for x in range(1,11)]\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d8516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog_bark            0.114521\n",
       "children_playing    0.114521\n",
       "air_conditioner     0.114521\n",
       "street_music        0.114521\n",
       "engine_idling       0.114521\n",
       "jackhammer          0.114521\n",
       "drilling            0.114521\n",
       "siren               0.106390\n",
       "car_horn            0.049130\n",
       "gun_shot            0.042831\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b17e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1855bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3555it [11:05,  5.42it/s]C:\\Users\\H\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  return f(*args, **kwargs)\n",
      "8325it [25:16,  9.90it/s]C:\\Users\\H\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  return f(*args, **kwargs)\n",
      "8329it [25:16, 15.45it/s]C:\\Users\\H\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  return f(*args, **kwargs)\n",
      "8732it [26:20,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4c7e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-217.35526, 70.22338, -130.38527, -53.282898,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.09818, 109.34077, -52.919525, 60.86475, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-458.79114, 121.38419, -46.520657, 52.00812, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-413.89984, 101.66373, -35.42945, 53.036354, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.60352, 113.68541, -52.402206, 60.302044,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-217.35526, 70.22338, -130.38527, -53.282898,...          dog_bark\n",
       "1  [-424.09818, 109.34077, -52.919525, 60.86475, ...  children_playing\n",
       "2  [-458.79114, 121.38419, -46.520657, 52.00812, ...  children_playing\n",
       "3  [-413.89984, 101.66373, -35.42945, 53.036354, ...  children_playing\n",
       "4  [-446.60352, 113.68541, -52.402206, 60.302044,...  children_playing"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75dc108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b323495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27982682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'children_playing', ...,\n",
       "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c03ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8d8a0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2777787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae2f0bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.31104706e+02,  1.12505905e+02, -2.25746956e+01, ...,\n",
       "         3.24665260e+00, -1.36902368e+00,  2.75575495e+00],\n",
       "       [-1.36703424e+01,  9.10850830e+01, -7.79273319e+00, ...,\n",
       "        -3.25305033e+00, -5.27745247e+00, -1.55697143e+00],\n",
       "       [-4.98715439e+01,  2.65352994e-01, -2.05009365e+01, ...,\n",
       "         2.85459447e+00, -1.60920441e+00,  3.52480578e+00],\n",
       "       ...,\n",
       "       [-4.27012360e+02,  9.26230469e+01,  3.12939739e+00, ...,\n",
       "         7.42641389e-01,  7.33490825e-01,  7.11009085e-01],\n",
       "       [-1.45754608e+02,  1.36265778e+02, -3.35155220e+01, ...,\n",
       "         1.46811950e+00, -2.00917006e+00, -8.82181883e-01],\n",
       "       [-4.21031342e+02,  2.10654541e+02,  3.49066067e+00, ...,\n",
       "        -5.38886738e+00, -3.37136054e+00, -1.56651151e+00]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b17029f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40a63cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 40)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb5230d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 40)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db283d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1430e5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ffe9131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "#Model creation\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e9957cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Activation, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(SimpleRNN(100, input_shape=(40, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6510b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f1ea18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### No of classes\n",
    "# num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf4cb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# ###first layer\n",
    "# model.add(Dense(100,input_shape=(40,)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# ###second layer\n",
    "# model.add(Dense(200))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# ###third layer\n",
    "# model.add(Dense(100))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# ###final layer\n",
    "# model.add(Dense(num_labels))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a32f1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9404062e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Final layer\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[43mnum_labels\u001b[49m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(Bidirectional(LSTM(100, input_shape=(40, 20), activation='tanh')))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Second layer\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final layer\n",
    "model.add(Dense(num_labels, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88c84e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29e7ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.3641 - accuracy: 0.1207\n",
      "Epoch 1: val_loss improved from inf to 2.20959, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 4s 77ms/step - loss: 2.3641 - accuracy: 0.1207 - val_loss: 2.2096 - val_accuracy: 0.1969\n",
      "Epoch 2/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.2128 - accuracy: 0.1687\n",
      "Epoch 2: val_loss improved from 2.20959 to 2.13432, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 2.2122 - accuracy: 0.1685 - val_loss: 2.1343 - val_accuracy: 0.2353\n",
      "Epoch 3/500\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 2.1648 - accuracy: 0.1878\n",
      "Epoch 3: val_loss improved from 2.13432 to 2.06740, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.1606 - accuracy: 0.1890 - val_loss: 2.0674 - val_accuracy: 0.2707\n",
      "Epoch 4/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.1049 - accuracy: 0.2095\n",
      "Epoch 4: val_loss improved from 2.06740 to 2.01570, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 2.1052 - accuracy: 0.2102 - val_loss: 2.0157 - val_accuracy: 0.2765\n",
      "Epoch 5/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.0616 - accuracy: 0.2313\n",
      "Epoch 5: val_loss improved from 2.01570 to 1.98567, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 2.0601 - accuracy: 0.2318 - val_loss: 1.9857 - val_accuracy: 0.2862\n",
      "Epoch 6/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.0260 - accuracy: 0.2380\n",
      "Epoch 6: val_loss improved from 1.98567 to 1.96823, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 2.0265 - accuracy: 0.2381 - val_loss: 1.9682 - val_accuracy: 0.3017\n",
      "Epoch 7/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.0029 - accuracy: 0.2451\n",
      "Epoch 7: val_loss improved from 1.96823 to 1.91750, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 2.0019 - accuracy: 0.2458 - val_loss: 1.9175 - val_accuracy: 0.3062\n",
      "Epoch 8/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9659 - accuracy: 0.2588\n",
      "Epoch 8: val_loss improved from 1.91750 to 1.88415, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.9647 - accuracy: 0.2580 - val_loss: 1.8842 - val_accuracy: 0.3205\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9423 - accuracy: 0.2636\n",
      "Epoch 9: val_loss improved from 1.88415 to 1.85086, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.9423 - accuracy: 0.2636 - val_loss: 1.8509 - val_accuracy: 0.3160\n",
      "Epoch 10/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9164 - accuracy: 0.2645\n",
      "Epoch 10: val_loss did not improve from 1.85086\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.9156 - accuracy: 0.2654 - val_loss: 1.8606 - val_accuracy: 0.3246\n",
      "Epoch 11/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9010 - accuracy: 0.2808\n",
      "Epoch 11: val_loss improved from 1.85086 to 1.83665, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.9007 - accuracy: 0.2806 - val_loss: 1.8367 - val_accuracy: 0.3148\n",
      "Epoch 12/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8846 - accuracy: 0.2814\n",
      "Epoch 12: val_loss improved from 1.83665 to 1.79580, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.8839 - accuracy: 0.2815 - val_loss: 1.7958 - val_accuracy: 0.3457\n",
      "Epoch 13/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8682 - accuracy: 0.2940\n",
      "Epoch 13: val_loss improved from 1.79580 to 1.78850, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.8690 - accuracy: 0.2942 - val_loss: 1.7885 - val_accuracy: 0.3434\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.8268 - accuracy: 0.2986\n",
      "Epoch 14: val_loss improved from 1.78850 to 1.75816, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.8268 - accuracy: 0.2986 - val_loss: 1.7582 - val_accuracy: 0.3429\n",
      "Epoch 15/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7852 - accuracy: 0.3027\n",
      "Epoch 15: val_loss did not improve from 1.75816\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.7868 - accuracy: 0.3014 - val_loss: 1.8428 - val_accuracy: 0.3143\n",
      "Epoch 16/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7974 - accuracy: 0.3119\n",
      "Epoch 16: val_loss improved from 1.75816 to 1.71971, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.7965 - accuracy: 0.3122 - val_loss: 1.7197 - val_accuracy: 0.3681\n",
      "Epoch 17/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7392 - accuracy: 0.3275\n",
      "Epoch 17: val_loss improved from 1.71971 to 1.68494, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.7393 - accuracy: 0.3273 - val_loss: 1.6849 - val_accuracy: 0.3595\n",
      "Epoch 18/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7338 - accuracy: 0.3370\n",
      "Epoch 18: val_loss improved from 1.68494 to 1.65704, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.7322 - accuracy: 0.3376 - val_loss: 1.6570 - val_accuracy: 0.3703\n",
      "Epoch 19/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7033 - accuracy: 0.3487\n",
      "Epoch 19: val_loss improved from 1.65704 to 1.64818, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.7023 - accuracy: 0.3490 - val_loss: 1.6482 - val_accuracy: 0.3801\n",
      "Epoch 20/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.7088 - accuracy: 0.3484\n",
      "Epoch 20: val_loss improved from 1.64818 to 1.63122, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.7089 - accuracy: 0.3493 - val_loss: 1.6312 - val_accuracy: 0.4013\n",
      "Epoch 21/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.6781 - accuracy: 0.3537\n",
      "Epoch 21: val_loss did not improve from 1.63122\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.6798 - accuracy: 0.3539 - val_loss: 1.6447 - val_accuracy: 0.4081\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6616 - accuracy: 0.3613\n",
      "Epoch 22: val_loss improved from 1.63122 to 1.60340, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.6616 - accuracy: 0.3613 - val_loss: 1.6034 - val_accuracy: 0.4333\n",
      "Epoch 23/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.6420 - accuracy: 0.3689\n",
      "Epoch 23: val_loss improved from 1.60340 to 1.59322, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 1.6415 - accuracy: 0.3688 - val_loss: 1.5932 - val_accuracy: 0.4224\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6338 - accuracy: 0.3790\n",
      "Epoch 24: val_loss improved from 1.59322 to 1.57399, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.6338 - accuracy: 0.3790 - val_loss: 1.5740 - val_accuracy: 0.4327\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6053 - accuracy: 0.3914\n",
      "Epoch 25: val_loss improved from 1.57399 to 1.53763, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 1.6053 - accuracy: 0.3914 - val_loss: 1.5376 - val_accuracy: 0.4471\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - ETA: 0s - loss: 1.5956 - accuracy: 0.3953\n",
      "Epoch 26: val_loss did not improve from 1.53763\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.5956 - accuracy: 0.3953 - val_loss: 1.5431 - val_accuracy: 0.4471\n",
      "Epoch 27/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5766 - accuracy: 0.3958\n",
      "Epoch 27: val_loss improved from 1.53763 to 1.52433, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 1.5764 - accuracy: 0.3961 - val_loss: 1.5243 - val_accuracy: 0.4654\n",
      "Epoch 28/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5277 - accuracy: 0.4220\n",
      "Epoch 28: val_loss improved from 1.52433 to 1.50528, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 1.5294 - accuracy: 0.4223 - val_loss: 1.5053 - val_accuracy: 0.4654\n",
      "Epoch 29/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5423 - accuracy: 0.4155\n",
      "Epoch 29: val_loss improved from 1.50528 to 1.45965, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 1.5429 - accuracy: 0.4157 - val_loss: 1.4596 - val_accuracy: 0.4619\n",
      "Epoch 30/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4915 - accuracy: 0.4320\n",
      "Epoch 30: val_loss did not improve from 1.45965\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 1.4916 - accuracy: 0.4315 - val_loss: 1.4714 - val_accuracy: 0.4705\n",
      "Epoch 31/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5241 - accuracy: 0.4298\n",
      "Epoch 31: val_loss did not improve from 1.45965\n",
      "28/28 [==============================] - 2s 60ms/step - loss: 1.5226 - accuracy: 0.4304 - val_loss: 1.4697 - val_accuracy: 0.4757\n",
      "Epoch 32/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4588 - accuracy: 0.4455\n",
      "Epoch 32: val_loss did not improve from 1.45965\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 1.4591 - accuracy: 0.4460 - val_loss: 1.4952 - val_accuracy: 0.4705\n",
      "Epoch 33/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4697 - accuracy: 0.4384\n",
      "Epoch 33: val_loss improved from 1.45965 to 1.41835, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 1.4674 - accuracy: 0.4389 - val_loss: 1.4183 - val_accuracy: 0.4820\n",
      "Epoch 34/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4263 - accuracy: 0.4612\n",
      "Epoch 34: val_loss improved from 1.41835 to 1.39902, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 1.4260 - accuracy: 0.4616 - val_loss: 1.3990 - val_accuracy: 0.4780\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4317 - accuracy: 0.4614\n",
      "Epoch 35: val_loss did not improve from 1.39902\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 1.4317 - accuracy: 0.4614 - val_loss: 1.4230 - val_accuracy: 0.4923\n",
      "Epoch 36/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4560 - accuracy: 0.4595\n",
      "Epoch 36: val_loss did not improve from 1.39902\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 1.4547 - accuracy: 0.4596 - val_loss: 1.4899 - val_accuracy: 0.4694\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4297 - accuracy: 0.4616\n",
      "Epoch 37: val_loss improved from 1.39902 to 1.36509, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 1.4297 - accuracy: 0.4616 - val_loss: 1.3651 - val_accuracy: 0.5100\n",
      "Epoch 38/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3724 - accuracy: 0.4828\n",
      "Epoch 38: val_loss improved from 1.36509 to 1.35005, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.3724 - accuracy: 0.4830 - val_loss: 1.3501 - val_accuracy: 0.5123\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3470 - accuracy: 0.4908\n",
      "Epoch 39: val_loss improved from 1.35005 to 1.33934, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.3470 - accuracy: 0.4908 - val_loss: 1.3393 - val_accuracy: 0.5026\n",
      "Epoch 40/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3393 - accuracy: 0.4970\n",
      "Epoch 40: val_loss improved from 1.33934 to 1.32268, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.3401 - accuracy: 0.4966 - val_loss: 1.3227 - val_accuracy: 0.5100\n",
      "Epoch 41/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3542 - accuracy: 0.4837\n",
      "Epoch 41: val_loss did not improve from 1.32268\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.3548 - accuracy: 0.4833 - val_loss: 1.3460 - val_accuracy: 0.5031\n",
      "Epoch 42/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3396 - accuracy: 0.4938\n",
      "Epoch 42: val_loss improved from 1.32268 to 1.28764, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.3408 - accuracy: 0.4932 - val_loss: 1.2876 - val_accuracy: 0.5135\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3220 - accuracy: 0.4999\n",
      "Epoch 43: val_loss improved from 1.28764 to 1.27109, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 1.3220 - accuracy: 0.4999 - val_loss: 1.2711 - val_accuracy: 0.5312\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3214 - accuracy: 0.4988\n",
      "Epoch 44: val_loss did not improve from 1.27109\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.3214 - accuracy: 0.4988 - val_loss: 1.3229 - val_accuracy: 0.5266\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3388 - accuracy: 0.4942\n",
      "Epoch 45: val_loss did not improve from 1.27109\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.3388 - accuracy: 0.4942 - val_loss: 1.3433 - val_accuracy: 0.4951\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3407 - accuracy: 0.4913\n",
      "Epoch 46: val_loss did not improve from 1.27109\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 1.3407 - accuracy: 0.4913 - val_loss: 1.3259 - val_accuracy: 0.5260\n",
      "Epoch 47/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3004 - accuracy: 0.5114\n",
      "Epoch 47: val_loss did not improve from 1.27109\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.3025 - accuracy: 0.5111 - val_loss: 1.2728 - val_accuracy: 0.5209\n",
      "Epoch 48/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2829 - accuracy: 0.5229\n",
      "Epoch 48: val_loss improved from 1.27109 to 1.25592, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2820 - accuracy: 0.5227 - val_loss: 1.2559 - val_accuracy: 0.5209\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2673 - accuracy: 0.5223\n",
      "Epoch 49: val_loss did not improve from 1.25592\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2673 - accuracy: 0.5223 - val_loss: 1.3355 - val_accuracy: 0.5135\n",
      "Epoch 50/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3222 - accuracy: 0.5052\n",
      "Epoch 50: val_loss did not improve from 1.25592\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.3223 - accuracy: 0.5041 - val_loss: 1.3717 - val_accuracy: 0.4837\n",
      "Epoch 51/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2910 - accuracy: 0.5124\n",
      "Epoch 51: val_loss did not improve from 1.25592\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.2900 - accuracy: 0.5127 - val_loss: 1.2684 - val_accuracy: 0.5352\n",
      "Epoch 52/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2571 - accuracy: 0.5276\n",
      "Epoch 52: val_loss improved from 1.25592 to 1.21644, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.2552 - accuracy: 0.5280 - val_loss: 1.2164 - val_accuracy: 0.5501\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2287 - accuracy: 0.5427\n",
      "Epoch 53: val_loss did not improve from 1.21644\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2280 - accuracy: 0.5427 - val_loss: 1.2713 - val_accuracy: 0.5421\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.5376\n",
      "Epoch 54: val_loss did not improve from 1.21644\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.2383 - accuracy: 0.5376 - val_loss: 1.3177 - val_accuracy: 0.5163\n",
      "Epoch 55/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2766 - accuracy: 0.5245\n",
      "Epoch 55: val_loss did not improve from 1.21644\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 1.2765 - accuracy: 0.5240 - val_loss: 1.2719 - val_accuracy: 0.5255\n",
      "Epoch 56/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2357 - accuracy: 0.5437\n",
      "Epoch 56: val_loss did not improve from 1.21644\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 1.2344 - accuracy: 0.5442 - val_loss: 1.2311 - val_accuracy: 0.5438\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2382 - accuracy: 0.5361\n",
      "Epoch 57: val_loss did not improve from 1.21644\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 1.2382 - accuracy: 0.5361 - val_loss: 1.2287 - val_accuracy: 0.5472\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1844 - accuracy: 0.5512\n",
      "Epoch 58: val_loss improved from 1.21644 to 1.20862, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 1.1844 - accuracy: 0.5512 - val_loss: 1.2086 - val_accuracy: 0.5644\n",
      "Epoch 59/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1739 - accuracy: 0.5613\n",
      "Epoch 59: val_loss improved from 1.20862 to 1.19739, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1738 - accuracy: 0.5608 - val_loss: 1.1974 - val_accuracy: 0.5552\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2083 - accuracy: 0.5568\n",
      "Epoch 60: val_loss did not improve from 1.19739\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.2083 - accuracy: 0.5568 - val_loss: 1.2598 - val_accuracy: 0.5449\n",
      "Epoch 61/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1934 - accuracy: 0.5598\n",
      "Epoch 61: val_loss did not improve from 1.19739\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.1947 - accuracy: 0.5589 - val_loss: 1.1976 - val_accuracy: 0.5587\n",
      "Epoch 62/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1769 - accuracy: 0.5547\n",
      "Epoch 62: val_loss improved from 1.19739 to 1.19663, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.1751 - accuracy: 0.5549 - val_loss: 1.1966 - val_accuracy: 0.5581\n",
      "Epoch 63/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1425 - accuracy: 0.5757\n",
      "Epoch 63: val_loss did not improve from 1.19663\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1461 - accuracy: 0.5744 - val_loss: 1.2332 - val_accuracy: 0.5524\n",
      "Epoch 64/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1504 - accuracy: 0.5667\n",
      "Epoch 64: val_loss did not improve from 1.19663\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.1512 - accuracy: 0.5668 - val_loss: 1.2041 - val_accuracy: 0.5621\n",
      "Epoch 65/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1539 - accuracy: 0.5725\n",
      "Epoch 65: val_loss did not improve from 1.19663\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.1536 - accuracy: 0.5715 - val_loss: 1.2091 - val_accuracy: 0.5398\n",
      "Epoch 66/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1607 - accuracy: 0.5702\n",
      "Epoch 66: val_loss did not improve from 1.19663\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.1614 - accuracy: 0.5694 - val_loss: 1.2167 - val_accuracy: 0.5535\n",
      "Epoch 67/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1336 - accuracy: 0.5888\n",
      "Epoch 67: val_loss improved from 1.19663 to 1.15003, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1337 - accuracy: 0.5881 - val_loss: 1.1500 - val_accuracy: 0.5850\n",
      "Epoch 68/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1340 - accuracy: 0.5849\n",
      "Epoch 68: val_loss did not improve from 1.15003\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 1.1360 - accuracy: 0.5843 - val_loss: 1.1861 - val_accuracy: 0.5690\n",
      "Epoch 69/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1648 - accuracy: 0.5774\n",
      "Epoch 69: val_loss did not improve from 1.15003\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.1655 - accuracy: 0.5775 - val_loss: 1.1890 - val_accuracy: 0.5747\n",
      "Epoch 70/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1316 - accuracy: 0.5826\n",
      "Epoch 70: val_loss did not improve from 1.15003\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.1298 - accuracy: 0.5830 - val_loss: 1.1538 - val_accuracy: 0.5810\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1129 - accuracy: 0.5885\n",
      "Epoch 71: val_loss did not improve from 1.15003\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.1129 - accuracy: 0.5885 - val_loss: 1.2150 - val_accuracy: 0.5558\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1209 - accuracy: 0.5910\n",
      "Epoch 72: val_loss did not improve from 1.15003\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1209 - accuracy: 0.5910 - val_loss: 1.1732 - val_accuracy: 0.5793\n",
      "Epoch 73/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0956 - accuracy: 0.5966\n",
      "Epoch 73: val_loss improved from 1.15003 to 1.13777, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.0952 - accuracy: 0.5967 - val_loss: 1.1378 - val_accuracy: 0.5890\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1124 - accuracy: 0.5900\n",
      "Epoch 74: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.1124 - accuracy: 0.5900 - val_loss: 1.1431 - val_accuracy: 0.5890\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1255 - accuracy: 0.5877\n",
      "Epoch 75: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.1255 - accuracy: 0.5877 - val_loss: 1.2211 - val_accuracy: 0.5644\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0980 - accuracy: 0.5960\n",
      "Epoch 76: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.0980 - accuracy: 0.5960 - val_loss: 1.1468 - val_accuracy: 0.5861\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0672 - accuracy: 0.6063\n",
      "Epoch 77: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.0672 - accuracy: 0.6063 - val_loss: 1.1387 - val_accuracy: 0.5884\n",
      "Epoch 78/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0994 - accuracy: 0.5987\n",
      "Epoch 78: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.0993 - accuracy: 0.5993 - val_loss: 1.1626 - val_accuracy: 0.5718\n",
      "Epoch 79/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0657 - accuracy: 0.6104\n",
      "Epoch 79: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.0645 - accuracy: 0.6105 - val_loss: 1.1582 - val_accuracy: 0.5781\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1732 - accuracy: 0.5761\n",
      "Epoch 80: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.1732 - accuracy: 0.5761 - val_loss: 1.2482 - val_accuracy: 0.5507\n",
      "Epoch 81/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1404 - accuracy: 0.5884\n",
      "Epoch 81: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.1398 - accuracy: 0.5890 - val_loss: 1.2050 - val_accuracy: 0.5610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2446 - accuracy: 0.5420\n",
      "Epoch 82: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.2431 - accuracy: 0.5423 - val_loss: 1.2070 - val_accuracy: 0.5598\n",
      "Epoch 83/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1231 - accuracy: 0.5868\n",
      "Epoch 83: val_loss did not improve from 1.13777\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.1205 - accuracy: 0.5885 - val_loss: 1.1690 - val_accuracy: 0.5839\n",
      "Epoch 84/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0718 - accuracy: 0.6037\n",
      "Epoch 84: val_loss improved from 1.13777 to 1.12658, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.0712 - accuracy: 0.6046 - val_loss: 1.1266 - val_accuracy: 0.5987\n",
      "Epoch 85/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0558 - accuracy: 0.6120\n",
      "Epoch 85: val_loss did not improve from 1.12658\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0540 - accuracy: 0.6129 - val_loss: 1.1447 - val_accuracy: 0.5816\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0581 - accuracy: 0.6143\n",
      "Epoch 86: val_loss improved from 1.12658 to 1.08212, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.0581 - accuracy: 0.6143 - val_loss: 1.0821 - val_accuracy: 0.6136\n",
      "Epoch 87/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0258 - accuracy: 0.6296\n",
      "Epoch 87: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.0254 - accuracy: 0.6299 - val_loss: 1.1607 - val_accuracy: 0.5970\n",
      "Epoch 88/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0716 - accuracy: 0.6127\n",
      "Epoch 88: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0722 - accuracy: 0.6123 - val_loss: 1.2172 - val_accuracy: 0.5575\n",
      "Epoch 89/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0803 - accuracy: 0.6078\n",
      "Epoch 89: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0816 - accuracy: 0.6072 - val_loss: 1.1838 - val_accuracy: 0.5695\n",
      "Epoch 90/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0593 - accuracy: 0.6182\n",
      "Epoch 90: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0587 - accuracy: 0.6185 - val_loss: 1.1488 - val_accuracy: 0.5879\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.6242\n",
      "Epoch 91: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.0286 - accuracy: 0.6242 - val_loss: 1.1170 - val_accuracy: 0.6068\n",
      "Epoch 92/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0477 - accuracy: 0.6212\n",
      "Epoch 92: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.0494 - accuracy: 0.6203 - val_loss: 1.1488 - val_accuracy: 0.5890\n",
      "Epoch 93/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0526 - accuracy: 0.6123\n",
      "Epoch 93: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0526 - accuracy: 0.6122 - val_loss: 1.1368 - val_accuracy: 0.5965\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0034 - accuracy: 0.6392\n",
      "Epoch 94: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.0034 - accuracy: 0.6392 - val_loss: 1.1391 - val_accuracy: 0.5953\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0560 - accuracy: 0.6157\n",
      "Epoch 95: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.0560 - accuracy: 0.6157 - val_loss: 1.1358 - val_accuracy: 0.5890\n",
      "Epoch 96/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0170 - accuracy: 0.6335\n",
      "Epoch 96: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0187 - accuracy: 0.6334 - val_loss: 1.1913 - val_accuracy: 0.5833\n",
      "Epoch 97/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0123 - accuracy: 0.6292\n",
      "Epoch 97: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.0111 - accuracy: 0.6289 - val_loss: 1.1232 - val_accuracy: 0.6085\n",
      "Epoch 98/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0077 - accuracy: 0.6400\n",
      "Epoch 98: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0086 - accuracy: 0.6399 - val_loss: 1.1372 - val_accuracy: 0.6005\n",
      "Epoch 99/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1219 - accuracy: 0.5959\n",
      "Epoch 99: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.1202 - accuracy: 0.5969 - val_loss: 1.1331 - val_accuracy: 0.5953\n",
      "Epoch 100/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0235 - accuracy: 0.6322\n",
      "Epoch 100: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0245 - accuracy: 0.6314 - val_loss: 1.1764 - val_accuracy: 0.5799\n",
      "Epoch 101/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0430 - accuracy: 0.6256\n",
      "Epoch 101: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.0452 - accuracy: 0.6245 - val_loss: 1.1022 - val_accuracy: 0.6119\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.6405\n",
      "Epoch 102: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.9971 - accuracy: 0.6405 - val_loss: 1.0908 - val_accuracy: 0.6085\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9861 - accuracy: 0.6385\n",
      "Epoch 103: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.9861 - accuracy: 0.6385 - val_loss: 1.1865 - val_accuracy: 0.5833\n",
      "Epoch 104/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9976 - accuracy: 0.6438\n",
      "Epoch 104: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9974 - accuracy: 0.6435 - val_loss: 1.0847 - val_accuracy: 0.6176\n",
      "Epoch 105/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9983 - accuracy: 0.6431\n",
      "Epoch 105: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.9994 - accuracy: 0.6428 - val_loss: 1.1054 - val_accuracy: 0.6211\n",
      "Epoch 106/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9944 - accuracy: 0.6434\n",
      "Epoch 106: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9928 - accuracy: 0.6444 - val_loss: 1.1492 - val_accuracy: 0.5987\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6525\n",
      "Epoch 107: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9607 - accuracy: 0.6525 - val_loss: 1.1265 - val_accuracy: 0.6331\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0591 - accuracy: 0.6220\n",
      "Epoch 108: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0591 - accuracy: 0.6220 - val_loss: 1.1537 - val_accuracy: 0.5867\n",
      "Epoch 109/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0861 - accuracy: 0.6107\n",
      "Epoch 109: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.0862 - accuracy: 0.6106 - val_loss: 1.1293 - val_accuracy: 0.6056\n",
      "Epoch 110/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1625 - accuracy: 0.5786\n",
      "Epoch 110: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.1623 - accuracy: 0.5792 - val_loss: 1.1451 - val_accuracy: 0.5993\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.6332\n",
      "Epoch 111: val_loss did not improve from 1.08212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0429 - accuracy: 0.6332 - val_loss: 1.1168 - val_accuracy: 0.6119\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.6464\n",
      "Epoch 112: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.0012 - accuracy: 0.6464 - val_loss: 1.0843 - val_accuracy: 0.6148\n",
      "Epoch 113/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9885 - accuracy: 0.6521\n",
      "Epoch 113: val_loss did not improve from 1.08212\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9869 - accuracy: 0.6523 - val_loss: 1.1202 - val_accuracy: 0.6205\n",
      "Epoch 114/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9708 - accuracy: 0.6502\n",
      "Epoch 114: val_loss improved from 1.08212 to 1.08143, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.9705 - accuracy: 0.6501 - val_loss: 1.0814 - val_accuracy: 0.6291\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9348 - accuracy: 0.6743\n",
      "Epoch 115: val_loss improved from 1.08143 to 1.06830, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.9348 - accuracy: 0.6743 - val_loss: 1.0683 - val_accuracy: 0.6348\n",
      "Epoch 116/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9546 - accuracy: 0.6591\n",
      "Epoch 116: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.9570 - accuracy: 0.6581 - val_loss: 1.1048 - val_accuracy: 0.6211\n",
      "Epoch 117/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9824 - accuracy: 0.6531\n",
      "Epoch 117: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9855 - accuracy: 0.6521 - val_loss: 1.1070 - val_accuracy: 0.6165\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.6258\n",
      "Epoch 118: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.0341 - accuracy: 0.6258 - val_loss: 1.1110 - val_accuracy: 0.6159\n",
      "Epoch 119/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0257 - accuracy: 0.6311\n",
      "Epoch 119: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.0246 - accuracy: 0.6312 - val_loss: 1.1102 - val_accuracy: 0.6234\n",
      "Epoch 120/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9606 - accuracy: 0.6655\n",
      "Epoch 120: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9623 - accuracy: 0.6653 - val_loss: 1.1130 - val_accuracy: 0.6239\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9447 - accuracy: 0.6684\n",
      "Epoch 121: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9447 - accuracy: 0.6684 - val_loss: 1.0959 - val_accuracy: 0.6405\n",
      "Epoch 122/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9276 - accuracy: 0.6781\n",
      "Epoch 122: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9280 - accuracy: 0.6780 - val_loss: 1.0938 - val_accuracy: 0.6337\n",
      "Epoch 123/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9577 - accuracy: 0.6596\n",
      "Epoch 123: val_loss did not improve from 1.06830\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9585 - accuracy: 0.6597 - val_loss: 1.0788 - val_accuracy: 0.6434\n",
      "Epoch 124/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9266 - accuracy: 0.6716\n",
      "Epoch 124: val_loss improved from 1.06830 to 1.05757, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.9278 - accuracy: 0.6709 - val_loss: 1.0576 - val_accuracy: 0.6445\n",
      "Epoch 125/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9307 - accuracy: 0.6685\n",
      "Epoch 125: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9303 - accuracy: 0.6679 - val_loss: 1.0933 - val_accuracy: 0.6291\n",
      "Epoch 126/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9964 - accuracy: 0.6554\n",
      "Epoch 126: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.9966 - accuracy: 0.6551 - val_loss: 1.2888 - val_accuracy: 0.5386\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1018 - accuracy: 0.6021\n",
      "Epoch 127: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.1018 - accuracy: 0.6021 - val_loss: 1.1515 - val_accuracy: 0.5936\n",
      "Epoch 128/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9924 - accuracy: 0.6509\n",
      "Epoch 128: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9900 - accuracy: 0.6524 - val_loss: 1.0758 - val_accuracy: 0.6256\n",
      "Epoch 129/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9895 - accuracy: 0.6454\n",
      "Epoch 129: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9910 - accuracy: 0.6450 - val_loss: 1.0916 - val_accuracy: 0.6297\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0017 - accuracy: 0.6487\n",
      "Epoch 130: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 1.0017 - accuracy: 0.6487 - val_loss: 1.1420 - val_accuracy: 0.6068\n",
      "Epoch 131/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9681 - accuracy: 0.6584\n",
      "Epoch 131: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9680 - accuracy: 0.6571 - val_loss: 1.0955 - val_accuracy: 0.6188\n",
      "Epoch 132/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9744 - accuracy: 0.6594\n",
      "Epoch 132: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.9745 - accuracy: 0.6593 - val_loss: 1.0883 - val_accuracy: 0.6342\n",
      "Epoch 133/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9665 - accuracy: 0.6586\n",
      "Epoch 133: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9678 - accuracy: 0.6576 - val_loss: 1.1285 - val_accuracy: 0.6056\n",
      "Epoch 134/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9834 - accuracy: 0.6486\n",
      "Epoch 134: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9830 - accuracy: 0.6485 - val_loss: 1.0793 - val_accuracy: 0.6297\n",
      "Epoch 135/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9222 - accuracy: 0.6787\n",
      "Epoch 135: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.9224 - accuracy: 0.6790 - val_loss: 1.0637 - val_accuracy: 0.6319\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.6664\n",
      "Epoch 136: val_loss did not improve from 1.05757\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9461 - accuracy: 0.6664 - val_loss: 1.0822 - val_accuracy: 0.6285\n",
      "Epoch 137/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9421 - accuracy: 0.6662\n",
      "Epoch 137: val_loss improved from 1.05757 to 1.05481, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 0.9428 - accuracy: 0.6659 - val_loss: 1.0548 - val_accuracy: 0.6325\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9229 - accuracy: 0.6653\n",
      "Epoch 138: val_loss improved from 1.05481 to 1.04034, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.9229 - accuracy: 0.6653 - val_loss: 1.0403 - val_accuracy: 0.6445\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.6872\n",
      "Epoch 139: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.8691 - accuracy: 0.6872 - val_loss: 1.0742 - val_accuracy: 0.6474\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9051 - accuracy: 0.6801\n",
      "Epoch 140: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.9049 - accuracy: 0.6799 - val_loss: 1.0754 - val_accuracy: 0.6422\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8899 - accuracy: 0.6915\n",
      "Epoch 141: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8899 - accuracy: 0.6915 - val_loss: 1.0660 - val_accuracy: 0.6417\n",
      "Epoch 142/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9246 - accuracy: 0.6716\n",
      "Epoch 142: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.9259 - accuracy: 0.6713 - val_loss: 1.0852 - val_accuracy: 0.6314\n",
      "Epoch 143/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9112 - accuracy: 0.6791\n",
      "Epoch 143: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.9108 - accuracy: 0.6795 - val_loss: 1.1298 - val_accuracy: 0.6199\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.6792\n",
      "Epoch 144: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9279 - accuracy: 0.6792 - val_loss: 1.0912 - val_accuracy: 0.6377\n",
      "Epoch 145/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8908 - accuracy: 0.6858\n",
      "Epoch 145: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8904 - accuracy: 0.6858 - val_loss: 1.0421 - val_accuracy: 0.6577\n",
      "Epoch 146/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9045 - accuracy: 0.6821\n",
      "Epoch 146: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9055 - accuracy: 0.6823 - val_loss: 1.0463 - val_accuracy: 0.6417\n",
      "Epoch 147/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8973 - accuracy: 0.6759\n",
      "Epoch 147: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8972 - accuracy: 0.6757 - val_loss: 1.0770 - val_accuracy: 0.6319\n",
      "Epoch 148/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8722 - accuracy: 0.6904\n",
      "Epoch 148: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8720 - accuracy: 0.6906 - val_loss: 1.0491 - val_accuracy: 0.6588\n",
      "Epoch 149/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9779 - accuracy: 0.6645\n",
      "Epoch 149: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9772 - accuracy: 0.6643 - val_loss: 1.2039 - val_accuracy: 0.5816\n",
      "Epoch 150/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9865 - accuracy: 0.6535\n",
      "Epoch 150: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9851 - accuracy: 0.6535 - val_loss: 1.1235 - val_accuracy: 0.6319\n",
      "Epoch 151/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0266 - accuracy: 0.6409\n",
      "Epoch 151: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0269 - accuracy: 0.6408 - val_loss: 1.1144 - val_accuracy: 0.6073\n",
      "Epoch 152/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9167 - accuracy: 0.6764\n",
      "Epoch 152: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9184 - accuracy: 0.6756 - val_loss: 1.1012 - val_accuracy: 0.6474\n",
      "Epoch 153/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9540 - accuracy: 0.6732\n",
      "Epoch 153: val_loss did not improve from 1.04034\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9531 - accuracy: 0.6733 - val_loss: 1.1580 - val_accuracy: 0.6251\n",
      "Epoch 154/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9875 - accuracy: 0.6622\n",
      "Epoch 154: val_loss improved from 1.04034 to 1.04025, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.9883 - accuracy: 0.6613 - val_loss: 1.0403 - val_accuracy: 0.6359\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9287 - accuracy: 0.6799\n",
      "Epoch 155: val_loss did not improve from 1.04025\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9287 - accuracy: 0.6799 - val_loss: 1.1504 - val_accuracy: 0.6165\n",
      "Epoch 156/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9215 - accuracy: 0.6827\n",
      "Epoch 156: val_loss improved from 1.04025 to 1.00358, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 0.9195 - accuracy: 0.6833 - val_loss: 1.0036 - val_accuracy: 0.6588\n",
      "Epoch 157/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8541 - accuracy: 0.7024\n",
      "Epoch 157: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.8537 - accuracy: 0.7019 - val_loss: 1.0188 - val_accuracy: 0.6600\n",
      "Epoch 158/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9043 - accuracy: 0.6868\n",
      "Epoch 158: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9039 - accuracy: 0.6869 - val_loss: 1.0654 - val_accuracy: 0.6520\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8939 - accuracy: 0.6890\n",
      "Epoch 159: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8939 - accuracy: 0.6890 - val_loss: 1.0824 - val_accuracy: 0.6234\n",
      "Epoch 160/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8597 - accuracy: 0.6973\n",
      "Epoch 160: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8579 - accuracy: 0.6984 - val_loss: 1.0069 - val_accuracy: 0.6571\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.6978\n",
      "Epoch 161: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8598 - accuracy: 0.6978 - val_loss: 1.0677 - val_accuracy: 0.6457\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9119 - accuracy: 0.6838\n",
      "Epoch 162: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9119 - accuracy: 0.6838 - val_loss: 1.1180 - val_accuracy: 0.6337\n",
      "Epoch 163/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9029 - accuracy: 0.6843\n",
      "Epoch 163: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9022 - accuracy: 0.6846 - val_loss: 1.0202 - val_accuracy: 0.6525\n",
      "Epoch 164/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8828 - accuracy: 0.6918\n",
      "Epoch 164: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8839 - accuracy: 0.6913 - val_loss: 1.0560 - val_accuracy: 0.6571\n",
      "Epoch 165/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8615 - accuracy: 0.6942\n",
      "Epoch 165: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8635 - accuracy: 0.6931 - val_loss: 1.0250 - val_accuracy: 0.6543\n",
      "Epoch 166/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8807 - accuracy: 0.6862\n",
      "Epoch 166: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8803 - accuracy: 0.6866 - val_loss: 1.0902 - val_accuracy: 0.6468\n",
      "Epoch 167/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8581 - accuracy: 0.7037\n",
      "Epoch 167: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8560 - accuracy: 0.7048 - val_loss: 1.0939 - val_accuracy: 0.6485\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.6853\n",
      "Epoch 168: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.9106 - accuracy: 0.6853 - val_loss: 1.1150 - val_accuracy: 0.6325\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9680 - accuracy: 0.6687\n",
      "Epoch 169: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 0.9708 - accuracy: 0.6683 - val_loss: 1.1553 - val_accuracy: 0.6417\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0276 - accuracy: 0.6437\n",
      "Epoch 170: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0276 - accuracy: 0.6437 - val_loss: 1.1436 - val_accuracy: 0.6205\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.6862\n",
      "Epoch 171: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.8846 - accuracy: 0.6862 - val_loss: 1.0507 - val_accuracy: 0.6537\n",
      "Epoch 172/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8423 - accuracy: 0.7067\n",
      "Epoch 172: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8428 - accuracy: 0.7072 - val_loss: 1.0530 - val_accuracy: 0.6577\n",
      "Epoch 173/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8441 - accuracy: 0.7020\n",
      "Epoch 173: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8459 - accuracy: 0.7018 - val_loss: 1.0361 - val_accuracy: 0.6560\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8293 - accuracy: 0.7041\n",
      "Epoch 174: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8293 - accuracy: 0.7041 - val_loss: 1.0551 - val_accuracy: 0.6417\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8429 - accuracy: 0.7127\n",
      "Epoch 175: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8429 - accuracy: 0.7127 - val_loss: 1.0147 - val_accuracy: 0.6554\n",
      "Epoch 176/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8777 - accuracy: 0.6913\n",
      "Epoch 176: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8785 - accuracy: 0.6911 - val_loss: 1.1843 - val_accuracy: 0.6251\n",
      "Epoch 177/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8492 - accuracy: 0.7021\n",
      "Epoch 177: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8501 - accuracy: 0.7019 - val_loss: 1.0770 - val_accuracy: 0.6629\n",
      "Epoch 178/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8719 - accuracy: 0.6991\n",
      "Epoch 178: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8711 - accuracy: 0.6998 - val_loss: 1.0780 - val_accuracy: 0.6405\n",
      "Epoch 179/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8813 - accuracy: 0.6960\n",
      "Epoch 179: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8826 - accuracy: 0.6946 - val_loss: 1.0338 - val_accuracy: 0.6503\n",
      "Epoch 180/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1275 - accuracy: 0.6014\n",
      "Epoch 180: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.1280 - accuracy: 0.6013 - val_loss: 1.2145 - val_accuracy: 0.5861\n",
      "Epoch 181/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0480 - accuracy: 0.6354\n",
      "Epoch 181: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0481 - accuracy: 0.6355 - val_loss: 1.0597 - val_accuracy: 0.6468\n",
      "Epoch 182/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8958 - accuracy: 0.6876\n",
      "Epoch 182: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8939 - accuracy: 0.6888 - val_loss: 1.0529 - val_accuracy: 0.6537\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9602 - accuracy: 0.6752\n",
      "Epoch 183: val_loss did not improve from 1.00358\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.9602 - accuracy: 0.6752 - val_loss: 1.0405 - val_accuracy: 0.6434\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.6981\n",
      "Epoch 184: val_loss improved from 1.00358 to 0.99949, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.8783 - accuracy: 0.6981 - val_loss: 0.9995 - val_accuracy: 0.6669\n",
      "Epoch 185/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8675 - accuracy: 0.6982\n",
      "Epoch 185: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8668 - accuracy: 0.6992 - val_loss: 1.0078 - val_accuracy: 0.6737\n",
      "Epoch 186/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8634 - accuracy: 0.6976\n",
      "Epoch 186: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8677 - accuracy: 0.6962 - val_loss: 1.1871 - val_accuracy: 0.6171\n",
      "Epoch 187/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9379 - accuracy: 0.6819\n",
      "Epoch 187: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9362 - accuracy: 0.6822 - val_loss: 1.0175 - val_accuracy: 0.6588\n",
      "Epoch 188/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8320 - accuracy: 0.7163\n",
      "Epoch 188: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8305 - accuracy: 0.7168 - val_loss: 1.0018 - val_accuracy: 0.6554\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8387 - accuracy: 0.7125\n",
      "Epoch 189: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8387 - accuracy: 0.7125 - val_loss: 1.0762 - val_accuracy: 0.6583\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0588 - accuracy: 0.6312\n",
      "Epoch 190: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.0588 - accuracy: 0.6312 - val_loss: 1.0550 - val_accuracy: 0.6440\n",
      "Epoch 191/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9227 - accuracy: 0.6797\n",
      "Epoch 191: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.9212 - accuracy: 0.6800 - val_loss: 1.1021 - val_accuracy: 0.6674\n",
      "Epoch 192/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8812 - accuracy: 0.6955\n",
      "Epoch 192: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8808 - accuracy: 0.6952 - val_loss: 1.0963 - val_accuracy: 0.6411\n",
      "Epoch 193/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9011 - accuracy: 0.6920\n",
      "Epoch 193: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.9004 - accuracy: 0.6923 - val_loss: 1.0616 - val_accuracy: 0.6508\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9440 - accuracy: 0.6800\n",
      "Epoch 194: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.9440 - accuracy: 0.6800 - val_loss: 1.0313 - val_accuracy: 0.6554\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8481 - accuracy: 0.7088\n",
      "Epoch 195: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8481 - accuracy: 0.7088 - val_loss: 1.0044 - val_accuracy: 0.6674\n",
      "Epoch 196/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8413 - accuracy: 0.7167\n",
      "Epoch 196: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8420 - accuracy: 0.7162 - val_loss: 1.0315 - val_accuracy: 0.6588\n",
      "Epoch 197/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8198 - accuracy: 0.7179\n",
      "Epoch 197: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8201 - accuracy: 0.7175 - val_loss: 1.0002 - val_accuracy: 0.6795\n",
      "Epoch 198/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8144 - accuracy: 0.7211\n",
      "Epoch 198: val_loss did not improve from 0.99949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8129 - accuracy: 0.7215 - val_loss: 1.0383 - val_accuracy: 0.6766\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.7145\n",
      "Epoch 199: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8424 - accuracy: 0.7145 - val_loss: 1.0054 - val_accuracy: 0.6691\n",
      "Epoch 200/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8878 - accuracy: 0.6907\n",
      "Epoch 200: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8909 - accuracy: 0.6906 - val_loss: 1.0678 - val_accuracy: 0.6400\n",
      "Epoch 201/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8855 - accuracy: 0.6888\n",
      "Epoch 201: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8843 - accuracy: 0.6893 - val_loss: 1.0325 - val_accuracy: 0.6726\n",
      "Epoch 202/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8371 - accuracy: 0.7134\n",
      "Epoch 202: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8359 - accuracy: 0.7137 - val_loss: 1.0539 - val_accuracy: 0.6617\n",
      "Epoch 203/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8322 - accuracy: 0.7170\n",
      "Epoch 203: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8318 - accuracy: 0.7177 - val_loss: 1.0179 - val_accuracy: 0.6669\n",
      "Epoch 204/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7950 - accuracy: 0.7290\n",
      "Epoch 204: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7976 - accuracy: 0.7280 - val_loss: 1.0836 - val_accuracy: 0.6474\n",
      "Epoch 205/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9797 - accuracy: 0.6709\n",
      "Epoch 205: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9767 - accuracy: 0.6719 - val_loss: 1.0855 - val_accuracy: 0.6291\n",
      "Epoch 206/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9287 - accuracy: 0.6811\n",
      "Epoch 206: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9278 - accuracy: 0.6807 - val_loss: 1.0288 - val_accuracy: 0.6611\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8567 - accuracy: 0.7077\n",
      "Epoch 207: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8567 - accuracy: 0.7077 - val_loss: 1.0297 - val_accuracy: 0.6835\n",
      "Epoch 208/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8424 - accuracy: 0.7135\n",
      "Epoch 208: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8419 - accuracy: 0.7137 - val_loss: 1.0864 - val_accuracy: 0.6623\n",
      "Epoch 209/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8248 - accuracy: 0.7099\n",
      "Epoch 209: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8269 - accuracy: 0.7099 - val_loss: 1.0059 - val_accuracy: 0.6760\n",
      "Epoch 210/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7719 - accuracy: 0.7364\n",
      "Epoch 210: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7723 - accuracy: 0.7366 - val_loss: 1.0108 - val_accuracy: 0.6789\n",
      "Epoch 211/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8109 - accuracy: 0.7232\n",
      "Epoch 211: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8103 - accuracy: 0.7236 - val_loss: 1.0259 - val_accuracy: 0.6669\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.7237\n",
      "Epoch 212: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7963 - accuracy: 0.7237 - val_loss: 1.1132 - val_accuracy: 0.6634\n",
      "Epoch 213/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8575 - accuracy: 0.7130\n",
      "Epoch 213: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8555 - accuracy: 0.7134 - val_loss: 1.0649 - val_accuracy: 0.6823\n",
      "Epoch 214/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8157 - accuracy: 0.7225\n",
      "Epoch 214: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8149 - accuracy: 0.7230 - val_loss: 1.0625 - val_accuracy: 0.6417\n",
      "Epoch 215/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8607 - accuracy: 0.7072\n",
      "Epoch 215: val_loss did not improve from 0.99949\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8617 - accuracy: 0.7072 - val_loss: 1.0435 - val_accuracy: 0.6531\n",
      "Epoch 216/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8216 - accuracy: 0.7192\n",
      "Epoch 216: val_loss improved from 0.99949 to 0.99547, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8200 - accuracy: 0.7195 - val_loss: 0.9955 - val_accuracy: 0.6795\n",
      "Epoch 217/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7775 - accuracy: 0.7283\n",
      "Epoch 217: val_loss did not improve from 0.99547\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7771 - accuracy: 0.7284 - val_loss: 1.0141 - val_accuracy: 0.6749\n",
      "Epoch 218/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8072 - accuracy: 0.7234\n",
      "Epoch 218: val_loss did not improve from 0.99547\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8066 - accuracy: 0.7238 - val_loss: 1.0172 - val_accuracy: 0.6835\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8395 - accuracy: 0.7120\n",
      "Epoch 219: val_loss improved from 0.99547 to 0.99049, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.8395 - accuracy: 0.7120 - val_loss: 0.9905 - val_accuracy: 0.6795\n",
      "Epoch 220/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8123 - accuracy: 0.7216\n",
      "Epoch 220: val_loss did not improve from 0.99049\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8106 - accuracy: 0.7223 - val_loss: 0.9985 - val_accuracy: 0.6714\n",
      "Epoch 221/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7776 - accuracy: 0.7302\n",
      "Epoch 221: val_loss did not improve from 0.99049\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7737 - accuracy: 0.7321 - val_loss: 0.9994 - val_accuracy: 0.6817\n",
      "Epoch 222/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7992 - accuracy: 0.7257\n",
      "Epoch 222: val_loss did not improve from 0.99049\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8000 - accuracy: 0.7253 - val_loss: 1.0270 - val_accuracy: 0.6703\n",
      "Epoch 223/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7985 - accuracy: 0.7222\n",
      "Epoch 223: val_loss improved from 0.99049 to 0.98551, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7990 - accuracy: 0.7221 - val_loss: 0.9855 - val_accuracy: 0.6829\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.7278\n",
      "Epoch 224: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7895 - accuracy: 0.7278 - val_loss: 1.0139 - val_accuracy: 0.6812\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.6679\n",
      "Epoch 225: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.0219 - accuracy: 0.6679 - val_loss: 1.4001 - val_accuracy: 0.5026\n",
      "Epoch 226/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1518 - accuracy: 0.5987\n",
      "Epoch 226: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 1.1485 - accuracy: 0.5996 - val_loss: 1.1823 - val_accuracy: 0.6245\n",
      "Epoch 227/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9376 - accuracy: 0.6834\n",
      "Epoch 227: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9372 - accuracy: 0.6839 - val_loss: 1.0502 - val_accuracy: 0.6543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8574 - accuracy: 0.7043\n",
      "Epoch 228: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8592 - accuracy: 0.7037 - val_loss: 1.0015 - val_accuracy: 0.6686\n",
      "Epoch 229/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8116 - accuracy: 0.7206\n",
      "Epoch 229: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8105 - accuracy: 0.7208 - val_loss: 1.0228 - val_accuracy: 0.6806\n",
      "Epoch 230/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8195 - accuracy: 0.7215\n",
      "Epoch 230: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8207 - accuracy: 0.7221 - val_loss: 1.0480 - val_accuracy: 0.6594\n",
      "Epoch 231/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8048 - accuracy: 0.7263\n",
      "Epoch 231: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8050 - accuracy: 0.7264 - val_loss: 1.0234 - val_accuracy: 0.6657\n",
      "Epoch 232/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8500 - accuracy: 0.7138\n",
      "Epoch 232: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8502 - accuracy: 0.7141 - val_loss: 1.0704 - val_accuracy: 0.6686\n",
      "Epoch 233/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8219 - accuracy: 0.7247\n",
      "Epoch 233: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8197 - accuracy: 0.7250 - val_loss: 0.9997 - val_accuracy: 0.6869\n",
      "Epoch 234/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7714 - accuracy: 0.7374\n",
      "Epoch 234: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7715 - accuracy: 0.7374 - val_loss: 1.0249 - val_accuracy: 0.6646\n",
      "Epoch 235/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8169 - accuracy: 0.7250\n",
      "Epoch 235: val_loss did not improve from 0.98551\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8164 - accuracy: 0.7250 - val_loss: 1.0119 - val_accuracy: 0.6674\n",
      "Epoch 236/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8030 - accuracy: 0.7273\n",
      "Epoch 236: val_loss improved from 0.98551 to 0.97877, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.8026 - accuracy: 0.7270 - val_loss: 0.9788 - val_accuracy: 0.6772\n",
      "Epoch 237/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8276 - accuracy: 0.7156\n",
      "Epoch 237: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8292 - accuracy: 0.7150 - val_loss: 1.0537 - val_accuracy: 0.6503\n",
      "Epoch 238/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7582 - accuracy: 0.7402\n",
      "Epoch 238: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7573 - accuracy: 0.7406 - val_loss: 1.0342 - val_accuracy: 0.6777\n",
      "Epoch 239/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7799 - accuracy: 0.7308\n",
      "Epoch 239: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7812 - accuracy: 0.7306 - val_loss: 1.0207 - val_accuracy: 0.6760\n",
      "Epoch 240/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7781 - accuracy: 0.7299\n",
      "Epoch 240: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7803 - accuracy: 0.7291 - val_loss: 1.0592 - val_accuracy: 0.6571\n",
      "Epoch 241/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9048 - accuracy: 0.6897\n",
      "Epoch 241: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9064 - accuracy: 0.6890 - val_loss: 1.1009 - val_accuracy: 0.6537\n",
      "Epoch 242/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8739 - accuracy: 0.7104\n",
      "Epoch 242: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8716 - accuracy: 0.7102 - val_loss: 0.9946 - val_accuracy: 0.6726\n",
      "Epoch 243/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8359 - accuracy: 0.7153\n",
      "Epoch 243: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8348 - accuracy: 0.7161 - val_loss: 1.0094 - val_accuracy: 0.6703\n",
      "Epoch 244/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8305 - accuracy: 0.7228\n",
      "Epoch 244: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8303 - accuracy: 0.7228 - val_loss: 0.9993 - val_accuracy: 0.6709\n",
      "Epoch 245/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8197 - accuracy: 0.7238\n",
      "Epoch 245: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8210 - accuracy: 0.7236 - val_loss: 1.0463 - val_accuracy: 0.6571\n",
      "Epoch 246/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8226 - accuracy: 0.7170\n",
      "Epoch 246: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8231 - accuracy: 0.7168 - val_loss: 1.0892 - val_accuracy: 0.6354\n",
      "Epoch 247/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8194 - accuracy: 0.7176\n",
      "Epoch 247: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8206 - accuracy: 0.7173 - val_loss: 1.0199 - val_accuracy: 0.6869\n",
      "Epoch 248/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8611 - accuracy: 0.7047\n",
      "Epoch 248: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8603 - accuracy: 0.7045 - val_loss: 1.0869 - val_accuracy: 0.6371\n",
      "Epoch 249/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2932 - accuracy: 0.5720\n",
      "Epoch 249: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.2892 - accuracy: 0.5731 - val_loss: 1.1219 - val_accuracy: 0.6302\n",
      "Epoch 250/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0693 - accuracy: 0.6382\n",
      "Epoch 250: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0694 - accuracy: 0.6377 - val_loss: 1.0726 - val_accuracy: 0.6359\n",
      "Epoch 251/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0360 - accuracy: 0.6434\n",
      "Epoch 251: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0346 - accuracy: 0.6434 - val_loss: 1.0636 - val_accuracy: 0.6428\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.6896\n",
      "Epoch 252: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8937 - accuracy: 0.6896 - val_loss: 1.0120 - val_accuracy: 0.6514\n",
      "Epoch 253/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8439 - accuracy: 0.7117\n",
      "Epoch 253: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8428 - accuracy: 0.7120 - val_loss: 1.0183 - val_accuracy: 0.6611\n",
      "Epoch 254/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7971 - accuracy: 0.7270\n",
      "Epoch 254: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7999 - accuracy: 0.7258 - val_loss: 1.0124 - val_accuracy: 0.6795\n",
      "Epoch 255/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8818 - accuracy: 0.6994\n",
      "Epoch 255: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8833 - accuracy: 0.6989 - val_loss: 1.0383 - val_accuracy: 0.6480\n",
      "Epoch 256/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8887 - accuracy: 0.6969\n",
      "Epoch 256: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8857 - accuracy: 0.6978 - val_loss: 1.0564 - val_accuracy: 0.6525\n",
      "Epoch 257/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8489 - accuracy: 0.7076\n",
      "Epoch 257: val_loss did not improve from 0.97877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8495 - accuracy: 0.7067 - val_loss: 1.0236 - val_accuracy: 0.6674\n",
      "Epoch 258/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8415 - accuracy: 0.7121\n",
      "Epoch 258: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8423 - accuracy: 0.7124 - val_loss: 1.0532 - val_accuracy: 0.6434\n",
      "Epoch 259/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8024 - accuracy: 0.7247\n",
      "Epoch 259: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8038 - accuracy: 0.7241 - val_loss: 1.0395 - val_accuracy: 0.6583\n",
      "Epoch 260/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8480 - accuracy: 0.7143\n",
      "Epoch 260: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8479 - accuracy: 0.7145 - val_loss: 1.0683 - val_accuracy: 0.6480\n",
      "Epoch 261/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8137 - accuracy: 0.7218\n",
      "Epoch 261: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8139 - accuracy: 0.7225 - val_loss: 0.9937 - val_accuracy: 0.6766\n",
      "Epoch 262/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8145 - accuracy: 0.7208\n",
      "Epoch 262: val_loss did not improve from 0.97877\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8123 - accuracy: 0.7213 - val_loss: 1.0449 - val_accuracy: 0.6457\n",
      "Epoch 263/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8381 - accuracy: 0.7102\n",
      "Epoch 263: val_loss improved from 0.97877 to 0.96329, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8382 - accuracy: 0.7095 - val_loss: 0.9633 - val_accuracy: 0.6823\n",
      "Epoch 264/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7526 - accuracy: 0.7380\n",
      "Epoch 264: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7528 - accuracy: 0.7379 - val_loss: 0.9747 - val_accuracy: 0.6783\n",
      "Epoch 265/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8158 - accuracy: 0.7219\n",
      "Epoch 265: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8169 - accuracy: 0.7215 - val_loss: 1.0058 - val_accuracy: 0.6611\n",
      "Epoch 266/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7953 - accuracy: 0.7306\n",
      "Epoch 266: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7951 - accuracy: 0.7309 - val_loss: 1.0184 - val_accuracy: 0.6657\n",
      "Epoch 267/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7678 - accuracy: 0.7361\n",
      "Epoch 267: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7709 - accuracy: 0.7350 - val_loss: 0.9876 - val_accuracy: 0.6749\n",
      "Epoch 268/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7855 - accuracy: 0.7380\n",
      "Epoch 268: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7848 - accuracy: 0.7384 - val_loss: 1.0133 - val_accuracy: 0.6732\n",
      "Epoch 269/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8051 - accuracy: 0.7235\n",
      "Epoch 269: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8061 - accuracy: 0.7236 - val_loss: 0.9973 - val_accuracy: 0.6760\n",
      "Epoch 270/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8094 - accuracy: 0.7273\n",
      "Epoch 270: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8115 - accuracy: 0.7264 - val_loss: 0.9935 - val_accuracy: 0.6720\n",
      "Epoch 271/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8038 - accuracy: 0.7251\n",
      "Epoch 271: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8043 - accuracy: 0.7250 - val_loss: 1.0175 - val_accuracy: 0.6577\n",
      "Epoch 272/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7595 - accuracy: 0.7386\n",
      "Epoch 272: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7601 - accuracy: 0.7387 - val_loss: 1.0325 - val_accuracy: 0.6697\n",
      "Epoch 273/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8034 - accuracy: 0.7253\n",
      "Epoch 273: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8024 - accuracy: 0.7256 - val_loss: 1.1274 - val_accuracy: 0.6783\n",
      "Epoch 274/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8173 - accuracy: 0.7274\n",
      "Epoch 274: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8169 - accuracy: 0.7276 - val_loss: 0.9959 - val_accuracy: 0.6691\n",
      "Epoch 275/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7566 - accuracy: 0.7422\n",
      "Epoch 275: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7550 - accuracy: 0.7423 - val_loss: 1.0099 - val_accuracy: 0.6703\n",
      "Epoch 276/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7599 - accuracy: 0.7420\n",
      "Epoch 276: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7575 - accuracy: 0.7432 - val_loss: 1.0576 - val_accuracy: 0.6749\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.7445\n",
      "Epoch 277: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7601 - accuracy: 0.7445 - val_loss: 0.9989 - val_accuracy: 0.6783\n",
      "Epoch 278/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7635 - accuracy: 0.7371\n",
      "Epoch 278: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7642 - accuracy: 0.7360 - val_loss: 1.0955 - val_accuracy: 0.6703\n",
      "Epoch 279/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7579 - accuracy: 0.7423\n",
      "Epoch 279: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7570 - accuracy: 0.7429 - val_loss: 1.0118 - val_accuracy: 0.6783\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7624 - accuracy: 0.7380\n",
      "Epoch 280: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7624 - accuracy: 0.7380 - val_loss: 0.9859 - val_accuracy: 0.6703\n",
      "Epoch 281/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7261 - accuracy: 0.7549\n",
      "Epoch 281: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7271 - accuracy: 0.7542 - val_loss: 0.9916 - val_accuracy: 0.6749\n",
      "Epoch 282/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7514 - accuracy: 0.7461\n",
      "Epoch 282: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7502 - accuracy: 0.7466 - val_loss: 0.9897 - val_accuracy: 0.6806\n",
      "Epoch 283/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8641 - accuracy: 0.7046\n",
      "Epoch 283: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8695 - accuracy: 0.7037 - val_loss: 1.0790 - val_accuracy: 0.6491\n",
      "Epoch 284/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8896 - accuracy: 0.6894\n",
      "Epoch 284: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8882 - accuracy: 0.6903 - val_loss: 0.9921 - val_accuracy: 0.6611\n",
      "Epoch 285/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7740 - accuracy: 0.7386\n",
      "Epoch 285: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7748 - accuracy: 0.7383 - val_loss: 0.9733 - val_accuracy: 0.6903\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.7423\n",
      "Epoch 286: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7480 - accuracy: 0.7423 - val_loss: 1.0141 - val_accuracy: 0.6611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7695 - accuracy: 0.7413\n",
      "Epoch 287: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7678 - accuracy: 0.7417 - val_loss: 1.1184 - val_accuracy: 0.6634\n",
      "Epoch 288/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7765 - accuracy: 0.7315\n",
      "Epoch 288: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7773 - accuracy: 0.7306 - val_loss: 1.0066 - val_accuracy: 0.6686\n",
      "Epoch 289/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9512 - accuracy: 0.6850\n",
      "Epoch 289: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.9487 - accuracy: 0.6862 - val_loss: 0.9677 - val_accuracy: 0.6835\n",
      "Epoch 290/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7964 - accuracy: 0.7306\n",
      "Epoch 290: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7947 - accuracy: 0.7313 - val_loss: 1.0788 - val_accuracy: 0.6691\n",
      "Epoch 291/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7840 - accuracy: 0.7348\n",
      "Epoch 291: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7844 - accuracy: 0.7343 - val_loss: 0.9738 - val_accuracy: 0.6898\n",
      "Epoch 292/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7781 - accuracy: 0.7358\n",
      "Epoch 292: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7769 - accuracy: 0.7359 - val_loss: 1.0115 - val_accuracy: 0.6674\n",
      "Epoch 293/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7377 - accuracy: 0.7493\n",
      "Epoch 293: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7367 - accuracy: 0.7497 - val_loss: 0.9972 - val_accuracy: 0.6875\n",
      "Epoch 294/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7687 - accuracy: 0.7399\n",
      "Epoch 294: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7686 - accuracy: 0.7397 - val_loss: 1.1057 - val_accuracy: 0.6852\n",
      "Epoch 295/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8974 - accuracy: 0.7031\n",
      "Epoch 295: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8958 - accuracy: 0.7035 - val_loss: 1.0372 - val_accuracy: 0.6714\n",
      "Epoch 296/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7667 - accuracy: 0.7377\n",
      "Epoch 296: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7661 - accuracy: 0.7383 - val_loss: 0.9697 - val_accuracy: 0.6754\n",
      "Epoch 297/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7966 - accuracy: 0.7297\n",
      "Epoch 297: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7973 - accuracy: 0.7293 - val_loss: 1.0112 - val_accuracy: 0.6703\n",
      "Epoch 298/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8427 - accuracy: 0.7193\n",
      "Epoch 298: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8426 - accuracy: 0.7190 - val_loss: 1.0991 - val_accuracy: 0.6365\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7983 - accuracy: 0.7223\n",
      "Epoch 299: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7983 - accuracy: 0.7223 - val_loss: 1.0283 - val_accuracy: 0.6886\n",
      "Epoch 300/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8204 - accuracy: 0.7195\n",
      "Epoch 300: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8213 - accuracy: 0.7191 - val_loss: 1.1120 - val_accuracy: 0.6400\n",
      "Epoch 301/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8254 - accuracy: 0.7133\n",
      "Epoch 301: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8262 - accuracy: 0.7127 - val_loss: 1.1601 - val_accuracy: 0.6531\n",
      "Epoch 302/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1955 - accuracy: 0.5896\n",
      "Epoch 302: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.1952 - accuracy: 0.5900 - val_loss: 1.1675 - val_accuracy: 0.5982\n",
      "Epoch 303/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9810 - accuracy: 0.6521\n",
      "Epoch 303: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9817 - accuracy: 0.6524 - val_loss: 1.0434 - val_accuracy: 0.6634\n",
      "Epoch 304/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9406 - accuracy: 0.6790\n",
      "Epoch 304: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9383 - accuracy: 0.6797 - val_loss: 1.0382 - val_accuracy: 0.6548\n",
      "Epoch 305/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8985 - accuracy: 0.6891\n",
      "Epoch 305: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8975 - accuracy: 0.6888 - val_loss: 1.0679 - val_accuracy: 0.6394\n",
      "Epoch 306/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8463 - accuracy: 0.7157\n",
      "Epoch 306: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8469 - accuracy: 0.7150 - val_loss: 1.0350 - val_accuracy: 0.6583\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8766 - accuracy: 0.7021\n",
      "Epoch 307: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8766 - accuracy: 0.7021 - val_loss: 1.0239 - val_accuracy: 0.6709\n",
      "Epoch 308/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7905 - accuracy: 0.7293\n",
      "Epoch 308: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7892 - accuracy: 0.7298 - val_loss: 1.0326 - val_accuracy: 0.6926\n",
      "Epoch 309/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8075 - accuracy: 0.7267\n",
      "Epoch 309: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8067 - accuracy: 0.7268 - val_loss: 0.9809 - val_accuracy: 0.6852\n",
      "Epoch 310/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8045 - accuracy: 0.7224\n",
      "Epoch 310: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8038 - accuracy: 0.7225 - val_loss: 1.0594 - val_accuracy: 0.6571\n",
      "Epoch 311/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8483 - accuracy: 0.7108\n",
      "Epoch 311: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8476 - accuracy: 0.7107 - val_loss: 1.0014 - val_accuracy: 0.6583\n",
      "Epoch 312/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7755 - accuracy: 0.7329\n",
      "Epoch 312: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7760 - accuracy: 0.7326 - val_loss: 0.9808 - val_accuracy: 0.6743\n",
      "Epoch 313/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7965 - accuracy: 0.7260\n",
      "Epoch 313: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7960 - accuracy: 0.7264 - val_loss: 0.9882 - val_accuracy: 0.6720\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7496 - accuracy: 0.7416\n",
      "Epoch 314: val_loss did not improve from 0.96329\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7496 - accuracy: 0.7416 - val_loss: 0.9689 - val_accuracy: 0.6880\n",
      "Epoch 315/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7661 - accuracy: 0.7436\n",
      "Epoch 315: val_loss improved from 0.96329 to 0.94982, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7644 - accuracy: 0.7437 - val_loss: 0.9498 - val_accuracy: 0.6915\n",
      "Epoch 316/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7701 - accuracy: 0.7354\n",
      "Epoch 316: val_loss did not improve from 0.94982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7727 - accuracy: 0.7349 - val_loss: 1.0261 - val_accuracy: 0.6726\n",
      "Epoch 317/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7842 - accuracy: 0.7339\n",
      "Epoch 317: val_loss did not improve from 0.94982\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7849 - accuracy: 0.7339 - val_loss: 1.0211 - val_accuracy: 0.6629\n",
      "Epoch 318/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7776 - accuracy: 0.7342\n",
      "Epoch 318: val_loss did not improve from 0.94982\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7783 - accuracy: 0.7344 - val_loss: 1.0225 - val_accuracy: 0.6829\n",
      "Epoch 319/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7765 - accuracy: 0.7365\n",
      "Epoch 319: val_loss did not improve from 0.94982\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7738 - accuracy: 0.7374 - val_loss: 1.0576 - val_accuracy: 0.6795\n",
      "Epoch 320/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7538 - accuracy: 0.7370\n",
      "Epoch 320: val_loss improved from 0.94982 to 0.93517, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7541 - accuracy: 0.7363 - val_loss: 0.9352 - val_accuracy: 0.6915\n",
      "Epoch 321/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7217 - accuracy: 0.7465\n",
      "Epoch 321: val_loss did not improve from 0.93517\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7194 - accuracy: 0.7472 - val_loss: 0.9673 - val_accuracy: 0.6880\n",
      "Epoch 322/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7306 - accuracy: 0.7562\n",
      "Epoch 322: val_loss did not improve from 0.93517\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7305 - accuracy: 0.7560 - val_loss: 0.9793 - val_accuracy: 0.6777\n",
      "Epoch 323/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7191 - accuracy: 0.7558\n",
      "Epoch 323: val_loss did not improve from 0.93517\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7190 - accuracy: 0.7556 - val_loss: 0.9785 - val_accuracy: 0.6955\n",
      "Epoch 324/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7323 - accuracy: 0.7483\n",
      "Epoch 324: val_loss did not improve from 0.93517\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7347 - accuracy: 0.7473 - val_loss: 0.9878 - val_accuracy: 0.6932\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7434 - accuracy: 0.7482\n",
      "Epoch 325: val_loss improved from 0.93517 to 0.93422, saving model to saved_models\\audio_classification.hdf5\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.7434 - accuracy: 0.7482 - val_loss: 0.9342 - val_accuracy: 0.6869\n",
      "Epoch 326/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7088 - accuracy: 0.7584\n",
      "Epoch 326: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7091 - accuracy: 0.7579 - val_loss: 0.9608 - val_accuracy: 0.6983\n",
      "Epoch 327/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7418 - accuracy: 0.7503\n",
      "Epoch 327: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7451 - accuracy: 0.7495 - val_loss: 1.2516 - val_accuracy: 0.6268\n",
      "Epoch 328/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9063 - accuracy: 0.6955\n",
      "Epoch 328: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9054 - accuracy: 0.6961 - val_loss: 1.0435 - val_accuracy: 0.6680\n",
      "Epoch 329/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9255 - accuracy: 0.6871\n",
      "Epoch 329: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9269 - accuracy: 0.6862 - val_loss: 1.2360 - val_accuracy: 0.5993\n",
      "Epoch 330/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9101 - accuracy: 0.6862\n",
      "Epoch 330: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9068 - accuracy: 0.6875 - val_loss: 1.0255 - val_accuracy: 0.6749\n",
      "Epoch 331/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8208 - accuracy: 0.7253\n",
      "Epoch 331: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8195 - accuracy: 0.7260 - val_loss: 0.9619 - val_accuracy: 0.6852\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.7487\n",
      "Epoch 332: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7599 - accuracy: 0.7487 - val_loss: 1.0170 - val_accuracy: 0.6789\n",
      "Epoch 333/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8028 - accuracy: 0.7280\n",
      "Epoch 333: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8013 - accuracy: 0.7288 - val_loss: 0.9913 - val_accuracy: 0.6846\n",
      "Epoch 334/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7652 - accuracy: 0.7374\n",
      "Epoch 334: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7662 - accuracy: 0.7370 - val_loss: 0.9817 - val_accuracy: 0.6772\n",
      "Epoch 335/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8048 - accuracy: 0.7318\n",
      "Epoch 335: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8045 - accuracy: 0.7313 - val_loss: 1.1135 - val_accuracy: 0.6365\n",
      "Epoch 336/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9085 - accuracy: 0.6902\n",
      "Epoch 336: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9086 - accuracy: 0.6903 - val_loss: 1.0113 - val_accuracy: 0.6749\n",
      "Epoch 337/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8148 - accuracy: 0.7245\n",
      "Epoch 337: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8149 - accuracy: 0.7247 - val_loss: 0.9560 - val_accuracy: 0.6835\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8253 - accuracy: 0.7296\n",
      "Epoch 338: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.8253 - accuracy: 0.7296 - val_loss: 1.1226 - val_accuracy: 0.6256\n",
      "Epoch 339/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8681 - accuracy: 0.6995\n",
      "Epoch 339: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8667 - accuracy: 0.6999 - val_loss: 0.9823 - val_accuracy: 0.6703\n",
      "Epoch 340/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7740 - accuracy: 0.7357\n",
      "Epoch 340: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7732 - accuracy: 0.7364 - val_loss: 1.0212 - val_accuracy: 0.6857\n",
      "Epoch 341/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7497 - accuracy: 0.7439\n",
      "Epoch 341: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7517 - accuracy: 0.7442 - val_loss: 1.0024 - val_accuracy: 0.6732\n",
      "Epoch 342/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7412 - accuracy: 0.7475\n",
      "Epoch 342: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7419 - accuracy: 0.7480 - val_loss: 0.9420 - val_accuracy: 0.6898\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.7472\n",
      "Epoch 343: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7472 - accuracy: 0.7472 - val_loss: 1.0258 - val_accuracy: 0.6697\n",
      "Epoch 344/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7610 - accuracy: 0.7405\n",
      "Epoch 344: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7612 - accuracy: 0.7409 - val_loss: 1.0432 - val_accuracy: 0.6531\n",
      "Epoch 345/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7261 - accuracy: 0.7530\n",
      "Epoch 345: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7248 - accuracy: 0.7535 - val_loss: 0.9858 - val_accuracy: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7509\n",
      "Epoch 346: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7339 - accuracy: 0.7509 - val_loss: 0.9967 - val_accuracy: 0.6817\n",
      "Epoch 347/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7129 - accuracy: 0.7587\n",
      "Epoch 347: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7124 - accuracy: 0.7595 - val_loss: 0.9914 - val_accuracy: 0.6823\n",
      "Epoch 348/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7101 - accuracy: 0.7565\n",
      "Epoch 348: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7083 - accuracy: 0.7571 - val_loss: 1.0813 - val_accuracy: 0.6468\n",
      "Epoch 349/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0351 - accuracy: 0.6481\n",
      "Epoch 349: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 1.0354 - accuracy: 0.6484 - val_loss: 1.1240 - val_accuracy: 0.6348\n",
      "Epoch 350/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8692 - accuracy: 0.7038\n",
      "Epoch 350: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8655 - accuracy: 0.7051 - val_loss: 0.9992 - val_accuracy: 0.6760\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7649 - accuracy: 0.7404\n",
      "Epoch 351: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.7649 - accuracy: 0.7404 - val_loss: 1.0084 - val_accuracy: 0.6898\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.7592\n",
      "Epoch 352: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7302 - accuracy: 0.7592 - val_loss: 1.0055 - val_accuracy: 0.6817\n",
      "Epoch 353/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7221 - accuracy: 0.7590\n",
      "Epoch 353: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 0.7225 - accuracy: 0.7586 - val_loss: 0.9998 - val_accuracy: 0.6989\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.7291\n",
      "Epoch 354: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.7835 - accuracy: 0.7291 - val_loss: 0.9920 - val_accuracy: 0.6817\n",
      "Epoch 355/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7262 - accuracy: 0.7529\n",
      "Epoch 355: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.7271 - accuracy: 0.7522 - val_loss: 0.9942 - val_accuracy: 0.6920\n",
      "Epoch 356/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7781 - accuracy: 0.7321\n",
      "Epoch 356: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7759 - accuracy: 0.7327 - val_loss: 0.9874 - val_accuracy: 0.6795\n",
      "Epoch 357/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7673 - accuracy: 0.7390\n",
      "Epoch 357: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 0.7664 - accuracy: 0.7392 - val_loss: 0.9534 - val_accuracy: 0.6875\n",
      "Epoch 358/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7348 - accuracy: 0.7530\n",
      "Epoch 358: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.7369 - accuracy: 0.7525 - val_loss: 0.9853 - val_accuracy: 0.6892\n",
      "Epoch 359/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7510 - accuracy: 0.7396\n",
      "Epoch 359: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 60ms/step - loss: 0.7491 - accuracy: 0.7406 - val_loss: 0.9825 - val_accuracy: 0.6852\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.7472\n",
      "Epoch 360: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7468 - accuracy: 0.7472 - val_loss: 1.0398 - val_accuracy: 0.6508\n",
      "Epoch 361/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7870 - accuracy: 0.7313\n",
      "Epoch 361: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.7884 - accuracy: 0.7311 - val_loss: 1.0318 - val_accuracy: 0.6611\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7716 - accuracy: 0.7469\n",
      "Epoch 362: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7716 - accuracy: 0.7469 - val_loss: 0.9840 - val_accuracy: 0.6886\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.7578\n",
      "Epoch 363: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7312 - accuracy: 0.7578 - val_loss: 0.9989 - val_accuracy: 0.6754\n",
      "Epoch 364/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8143 - accuracy: 0.7190\n",
      "Epoch 364: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.8155 - accuracy: 0.7190 - val_loss: 0.9771 - val_accuracy: 0.7001\n",
      "Epoch 365/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7594 - accuracy: 0.7396\n",
      "Epoch 365: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7587 - accuracy: 0.7403 - val_loss: 0.9661 - val_accuracy: 0.6966\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.7566\n",
      "Epoch 366: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7257 - accuracy: 0.7566 - val_loss: 0.9517 - val_accuracy: 0.7075\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7152 - accuracy: 0.7589\n",
      "Epoch 367: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7152 - accuracy: 0.7589 - val_loss: 0.9809 - val_accuracy: 0.6892\n",
      "Epoch 368/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7228 - accuracy: 0.7591\n",
      "Epoch 368: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7227 - accuracy: 0.7596 - val_loss: 0.9701 - val_accuracy: 0.7023\n",
      "Epoch 369/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7424 - accuracy: 0.7535\n",
      "Epoch 369: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7432 - accuracy: 0.7530 - val_loss: 0.9816 - val_accuracy: 0.6772\n",
      "Epoch 370/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7359 - accuracy: 0.7546\n",
      "Epoch 370: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7355 - accuracy: 0.7548 - val_loss: 1.0948 - val_accuracy: 0.6840\n",
      "Epoch 371/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8073 - accuracy: 0.7338\n",
      "Epoch 371: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8051 - accuracy: 0.7346 - val_loss: 0.9458 - val_accuracy: 0.6875\n",
      "Epoch 372/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7402 - accuracy: 0.7504\n",
      "Epoch 372: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7423 - accuracy: 0.7493 - val_loss: 0.9630 - val_accuracy: 0.6903\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.7542\n",
      "Epoch 373: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.7226 - accuracy: 0.7542 - val_loss: 0.9681 - val_accuracy: 0.6966\n",
      "Epoch 374/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7158 - accuracy: 0.7606\n",
      "Epoch 374: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7150 - accuracy: 0.7611 - val_loss: 0.9876 - val_accuracy: 0.6835\n",
      "Epoch 375/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6942 - accuracy: 0.7687\n",
      "Epoch 375: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6925 - accuracy: 0.7698 - val_loss: 0.9958 - val_accuracy: 0.7086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7533 - accuracy: 0.7591\n",
      "Epoch 376: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7528 - accuracy: 0.7591 - val_loss: 0.9874 - val_accuracy: 0.6983\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7795 - accuracy: 0.7406\n",
      "Epoch 377: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7795 - accuracy: 0.7406 - val_loss: 1.0612 - val_accuracy: 0.6743\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8027 - accuracy: 0.7286\n",
      "Epoch 378: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8027 - accuracy: 0.7286 - val_loss: 1.0590 - val_accuracy: 0.6480\n",
      "Epoch 379/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7548 - accuracy: 0.7468\n",
      "Epoch 379: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.7539 - accuracy: 0.7472 - val_loss: 0.9599 - val_accuracy: 0.6857\n",
      "Epoch 380/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7108 - accuracy: 0.7543\n",
      "Epoch 380: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.7116 - accuracy: 0.7538 - val_loss: 0.9814 - val_accuracy: 0.6898\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.7480\n",
      "Epoch 381: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7350 - accuracy: 0.7480 - val_loss: 1.0258 - val_accuracy: 0.6772\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.7522\n",
      "Epoch 382: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7332 - accuracy: 0.7522 - val_loss: 0.9959 - val_accuracy: 0.6972\n",
      "Epoch 383/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7439 - accuracy: 0.7462\n",
      "Epoch 383: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7429 - accuracy: 0.7472 - val_loss: 0.9910 - val_accuracy: 0.6737\n",
      "Epoch 384/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7149 - accuracy: 0.7546\n",
      "Epoch 384: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.7147 - accuracy: 0.7546 - val_loss: 1.0222 - val_accuracy: 0.6709\n",
      "Epoch 385/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7133 - accuracy: 0.7614\n",
      "Epoch 385: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7172 - accuracy: 0.7603 - val_loss: 1.0430 - val_accuracy: 0.6651\n",
      "Epoch 386/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9345 - accuracy: 0.6888\n",
      "Epoch 386: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.9330 - accuracy: 0.6890 - val_loss: 1.1771 - val_accuracy: 0.6674\n",
      "Epoch 387/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8205 - accuracy: 0.7216\n",
      "Epoch 387: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8223 - accuracy: 0.7204 - val_loss: 1.0310 - val_accuracy: 0.6646\n",
      "Epoch 388/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7496 - accuracy: 0.7449\n",
      "Epoch 388: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7505 - accuracy: 0.7449 - val_loss: 1.0149 - val_accuracy: 0.6829\n",
      "Epoch 389/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7347 - accuracy: 0.7491\n",
      "Epoch 389: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7332 - accuracy: 0.7497 - val_loss: 0.9712 - val_accuracy: 0.7029\n",
      "Epoch 390/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7577 - accuracy: 0.7454\n",
      "Epoch 390: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7593 - accuracy: 0.7443 - val_loss: 0.9890 - val_accuracy: 0.6789\n",
      "Epoch 391/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7459 - accuracy: 0.7451\n",
      "Epoch 391: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7469 - accuracy: 0.7447 - val_loss: 1.0224 - val_accuracy: 0.6720\n",
      "Epoch 392/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7774 - accuracy: 0.7403\n",
      "Epoch 392: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7772 - accuracy: 0.7403 - val_loss: 0.9766 - val_accuracy: 0.6840\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.7399\n",
      "Epoch 393: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.7604 - accuracy: 0.7399 - val_loss: 1.0207 - val_accuracy: 0.6651\n",
      "Epoch 394/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7991 - accuracy: 0.7247\n",
      "Epoch 394: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7990 - accuracy: 0.7246 - val_loss: 1.1939 - val_accuracy: 0.6766\n",
      "Epoch 395/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7973 - accuracy: 0.7292\n",
      "Epoch 395: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.7967 - accuracy: 0.7291 - val_loss: 1.0561 - val_accuracy: 0.6365\n",
      "Epoch 396/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8005 - accuracy: 0.7287\n",
      "Epoch 396: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8001 - accuracy: 0.7290 - val_loss: 0.9923 - val_accuracy: 0.6766\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7417 - accuracy: 0.7546\n",
      "Epoch 397: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7417 - accuracy: 0.7546 - val_loss: 1.0396 - val_accuracy: 0.6789\n",
      "Epoch 398/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7878 - accuracy: 0.7363\n",
      "Epoch 398: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7875 - accuracy: 0.7360 - val_loss: 0.9725 - val_accuracy: 0.6966\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.7586\n",
      "Epoch 399: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.7327 - accuracy: 0.7586 - val_loss: 1.0079 - val_accuracy: 0.6737\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.7475\n",
      "Epoch 400: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.7486 - accuracy: 0.7475 - val_loss: 1.0199 - val_accuracy: 0.7023\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7961 - accuracy: 0.7313\n",
      "Epoch 401: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7961 - accuracy: 0.7313 - val_loss: 0.9603 - val_accuracy: 0.6943\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7358 - accuracy: 0.7545\n",
      "Epoch 402: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7358 - accuracy: 0.7545 - val_loss: 0.9836 - val_accuracy: 0.6909\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.7369\n",
      "Epoch 403: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7683 - accuracy: 0.7369 - val_loss: 1.1297 - val_accuracy: 0.6709\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8037 - accuracy: 0.7306\n",
      "Epoch 404: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.8037 - accuracy: 0.7306 - val_loss: 1.2085 - val_accuracy: 0.6142\n",
      "Epoch 405/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0454 - accuracy: 0.6534\n",
      "Epoch 405: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0456 - accuracy: 0.6534 - val_loss: 1.0205 - val_accuracy: 0.6543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8600 - accuracy: 0.7098\n",
      "Epoch 406: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8589 - accuracy: 0.7108 - val_loss: 0.9964 - val_accuracy: 0.6726\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.7512\n",
      "Epoch 407: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7476 - accuracy: 0.7512 - val_loss: 0.9550 - val_accuracy: 0.6978\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.7639\n",
      "Epoch 408: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.7050 - accuracy: 0.7639 - val_loss: 0.9979 - val_accuracy: 0.6898\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7636 - accuracy: 0.7480\n",
      "Epoch 409: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7636 - accuracy: 0.7480 - val_loss: 0.9928 - val_accuracy: 0.6875\n",
      "Epoch 410/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7366 - accuracy: 0.7530\n",
      "Epoch 410: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7363 - accuracy: 0.7533 - val_loss: 1.0082 - val_accuracy: 0.6938\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.7735\n",
      "Epoch 411: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6747 - accuracy: 0.7735 - val_loss: 1.0364 - val_accuracy: 0.6926\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.7635\n",
      "Epoch 412: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.7059 - accuracy: 0.7635 - val_loss: 1.0118 - val_accuracy: 0.6772\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.7629\n",
      "Epoch 413: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.6976 - accuracy: 0.7629 - val_loss: 1.0224 - val_accuracy: 0.7001\n",
      "Epoch 414/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7440 - accuracy: 0.7548\n",
      "Epoch 414: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7435 - accuracy: 0.7550 - val_loss: 1.1459 - val_accuracy: 0.6651\n",
      "Epoch 415/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9995 - accuracy: 0.6791\n",
      "Epoch 415: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.9976 - accuracy: 0.6797 - val_loss: 1.0780 - val_accuracy: 0.6417\n",
      "Epoch 416/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8234 - accuracy: 0.7231\n",
      "Epoch 416: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8266 - accuracy: 0.7220 - val_loss: 1.0241 - val_accuracy: 0.6760\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7972 - accuracy: 0.7364\n",
      "Epoch 417: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7972 - accuracy: 0.7364 - val_loss: 0.9781 - val_accuracy: 0.6898\n",
      "Epoch 418/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7416 - accuracy: 0.7558\n",
      "Epoch 418: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7408 - accuracy: 0.7562 - val_loss: 0.9650 - val_accuracy: 0.7006\n",
      "Epoch 419/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6988 - accuracy: 0.7677\n",
      "Epoch 419: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.6990 - accuracy: 0.7678 - val_loss: 0.9630 - val_accuracy: 0.6909\n",
      "Epoch 420/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6699 - accuracy: 0.7772\n",
      "Epoch 420: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6713 - accuracy: 0.7771 - val_loss: 1.0503 - val_accuracy: 0.7086\n",
      "Epoch 421/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9064 - accuracy: 0.7098\n",
      "Epoch 421: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.9076 - accuracy: 0.7092 - val_loss: 1.0823 - val_accuracy: 0.6525\n",
      "Epoch 422/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8094 - accuracy: 0.7309\n",
      "Epoch 422: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8088 - accuracy: 0.7317 - val_loss: 1.0350 - val_accuracy: 0.6566\n",
      "Epoch 423/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7500 - accuracy: 0.7520\n",
      "Epoch 423: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7512 - accuracy: 0.7515 - val_loss: 0.9357 - val_accuracy: 0.7041\n",
      "Epoch 424/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7236 - accuracy: 0.7585\n",
      "Epoch 424: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7242 - accuracy: 0.7582 - val_loss: 0.9881 - val_accuracy: 0.6938\n",
      "Epoch 425/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7297 - accuracy: 0.7556\n",
      "Epoch 425: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7283 - accuracy: 0.7565 - val_loss: 0.9363 - val_accuracy: 0.6995\n",
      "Epoch 426/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7873 - accuracy: 0.7368\n",
      "Epoch 426: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7888 - accuracy: 0.7360 - val_loss: 0.9651 - val_accuracy: 0.6892\n",
      "Epoch 427/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7246 - accuracy: 0.7561\n",
      "Epoch 427: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7256 - accuracy: 0.7563 - val_loss: 1.0444 - val_accuracy: 0.6634\n",
      "Epoch 428/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7354 - accuracy: 0.7525\n",
      "Epoch 428: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.7358 - accuracy: 0.7520 - val_loss: 0.9884 - val_accuracy: 0.6932\n",
      "Epoch 429/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7186 - accuracy: 0.7565\n",
      "Epoch 429: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7203 - accuracy: 0.7563 - val_loss: 0.9589 - val_accuracy: 0.6898\n",
      "Epoch 430/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8044 - accuracy: 0.7335\n",
      "Epoch 430: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8013 - accuracy: 0.7346 - val_loss: 0.9800 - val_accuracy: 0.6732\n",
      "Epoch 431/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7401 - accuracy: 0.7523\n",
      "Epoch 431: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7416 - accuracy: 0.7522 - val_loss: 1.1475 - val_accuracy: 0.6754\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8836 - accuracy: 0.7088\n",
      "Epoch 432: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8836 - accuracy: 0.7088 - val_loss: 1.2338 - val_accuracy: 0.5965\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.7254\n",
      "Epoch 433: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.8171 - accuracy: 0.7254 - val_loss: 0.9869 - val_accuracy: 0.6674\n",
      "Epoch 434/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7757 - accuracy: 0.7407\n",
      "Epoch 434: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 0.7755 - accuracy: 0.7413 - val_loss: 0.9786 - val_accuracy: 0.6880\n",
      "Epoch 435/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8051 - accuracy: 0.7308\n",
      "Epoch 435: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8056 - accuracy: 0.7307 - val_loss: 1.0061 - val_accuracy: 0.6714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7698 - accuracy: 0.7393\n",
      "Epoch 436: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7690 - accuracy: 0.7396 - val_loss: 0.9749 - val_accuracy: 0.6852\n",
      "Epoch 437/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8374 - accuracy: 0.7169\n",
      "Epoch 437: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8376 - accuracy: 0.7170 - val_loss: 1.1692 - val_accuracy: 0.6640\n",
      "Epoch 438/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8220 - accuracy: 0.7241\n",
      "Epoch 438: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8221 - accuracy: 0.7238 - val_loss: 0.9948 - val_accuracy: 0.6783\n",
      "Epoch 439/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7401 - accuracy: 0.7484\n",
      "Epoch 439: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7395 - accuracy: 0.7483 - val_loss: 1.0275 - val_accuracy: 0.6972\n",
      "Epoch 440/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7348 - accuracy: 0.7546\n",
      "Epoch 440: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7345 - accuracy: 0.7545 - val_loss: 1.0241 - val_accuracy: 0.6743\n",
      "Epoch 441/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7275 - accuracy: 0.7564\n",
      "Epoch 441: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7266 - accuracy: 0.7565 - val_loss: 0.9806 - val_accuracy: 0.6829\n",
      "Epoch 442/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7283 - accuracy: 0.7526\n",
      "Epoch 442: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7285 - accuracy: 0.7526 - val_loss: 1.0111 - val_accuracy: 0.6943\n",
      "Epoch 443/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7268 - accuracy: 0.7587\n",
      "Epoch 443: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7270 - accuracy: 0.7581 - val_loss: 0.9696 - val_accuracy: 0.6972\n",
      "Epoch 444/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7046 - accuracy: 0.7646\n",
      "Epoch 444: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7030 - accuracy: 0.7651 - val_loss: 0.9979 - val_accuracy: 0.6835\n",
      "Epoch 445/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7004 - accuracy: 0.7627\n",
      "Epoch 445: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7012 - accuracy: 0.7619 - val_loss: 1.0084 - val_accuracy: 0.7104\n",
      "Epoch 446/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7678 - accuracy: 0.7471\n",
      "Epoch 446: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7694 - accuracy: 0.7470 - val_loss: 1.0104 - val_accuracy: 0.6697\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.7545\n",
      "Epoch 447: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7445 - accuracy: 0.7545 - val_loss: 1.0580 - val_accuracy: 0.6525\n",
      "Epoch 448/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8379 - accuracy: 0.7229\n",
      "Epoch 448: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8381 - accuracy: 0.7233 - val_loss: 1.0562 - val_accuracy: 0.6663\n",
      "Epoch 449/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7152 - accuracy: 0.7611\n",
      "Epoch 449: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7149 - accuracy: 0.7605 - val_loss: 1.0011 - val_accuracy: 0.6760\n",
      "Epoch 450/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7586 - accuracy: 0.7446\n",
      "Epoch 450: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7584 - accuracy: 0.7442 - val_loss: 1.0018 - val_accuracy: 0.6903\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7384 - accuracy: 0.7568\n",
      "Epoch 451: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7384 - accuracy: 0.7568 - val_loss: 1.0549 - val_accuracy: 0.6806\n",
      "Epoch 452/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7761 - accuracy: 0.7420\n",
      "Epoch 452: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7743 - accuracy: 0.7422 - val_loss: 0.9948 - val_accuracy: 0.6880\n",
      "Epoch 453/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7081 - accuracy: 0.7626\n",
      "Epoch 453: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7084 - accuracy: 0.7622 - val_loss: 1.0115 - val_accuracy: 0.6835\n",
      "Epoch 454/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.7672\n",
      "Epoch 454: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.6899 - accuracy: 0.7681 - val_loss: 0.9953 - val_accuracy: 0.6926\n",
      "Epoch 455/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7097 - accuracy: 0.7623\n",
      "Epoch 455: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7112 - accuracy: 0.7619 - val_loss: 1.0502 - val_accuracy: 0.6857\n",
      "Epoch 456/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6861 - accuracy: 0.7663\n",
      "Epoch 456: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.6867 - accuracy: 0.7666 - val_loss: 0.9764 - val_accuracy: 0.6972\n",
      "Epoch 457/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7751 - accuracy: 0.7355\n",
      "Epoch 457: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7735 - accuracy: 0.7364 - val_loss: 1.0158 - val_accuracy: 0.6806\n",
      "Epoch 458/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6906 - accuracy: 0.7688\n",
      "Epoch 458: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.6906 - accuracy: 0.7688 - val_loss: 0.9729 - val_accuracy: 0.7035\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6760 - accuracy: 0.7727\n",
      "Epoch 459: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6760 - accuracy: 0.7727 - val_loss: 1.0007 - val_accuracy: 0.6938\n",
      "Epoch 460/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8047 - accuracy: 0.7381\n",
      "Epoch 460: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8042 - accuracy: 0.7383 - val_loss: 1.0536 - val_accuracy: 0.6623\n",
      "Epoch 461/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8616 - accuracy: 0.7121\n",
      "Epoch 461: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8614 - accuracy: 0.7122 - val_loss: 1.0636 - val_accuracy: 0.6468\n",
      "Epoch 462/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7985 - accuracy: 0.7302\n",
      "Epoch 462: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7990 - accuracy: 0.7301 - val_loss: 0.9805 - val_accuracy: 0.6869\n",
      "Epoch 463/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7234 - accuracy: 0.7617\n",
      "Epoch 463: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7238 - accuracy: 0.7611 - val_loss: 1.0259 - val_accuracy: 0.6760\n",
      "Epoch 464/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7166 - accuracy: 0.7594\n",
      "Epoch 464: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7162 - accuracy: 0.7593 - val_loss: 0.9901 - val_accuracy: 0.6880\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7780\n",
      "Epoch 465: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.6667 - accuracy: 0.7780 - val_loss: 0.9855 - val_accuracy: 0.6903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6986 - accuracy: 0.7694\n",
      "Epoch 466: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.6976 - accuracy: 0.7696 - val_loss: 0.9408 - val_accuracy: 0.7052\n",
      "Epoch 467/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7168 - accuracy: 0.7603\n",
      "Epoch 467: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7187 - accuracy: 0.7589 - val_loss: 1.1249 - val_accuracy: 0.6743\n",
      "Epoch 468/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3249 - accuracy: 0.5744\n",
      "Epoch 468: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.3254 - accuracy: 0.5747 - val_loss: 1.3366 - val_accuracy: 0.5890\n",
      "Epoch 469/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1252 - accuracy: 0.6204\n",
      "Epoch 469: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.1225 - accuracy: 0.6213 - val_loss: 1.1058 - val_accuracy: 0.6308\n",
      "Epoch 470/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0335 - accuracy: 0.6468\n",
      "Epoch 470: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.0315 - accuracy: 0.6478 - val_loss: 1.1149 - val_accuracy: 0.6285\n",
      "Epoch 471/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9323 - accuracy: 0.6810\n",
      "Epoch 471: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.9302 - accuracy: 0.6812 - val_loss: 1.1359 - val_accuracy: 0.6388\n",
      "Epoch 472/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8904 - accuracy: 0.7056\n",
      "Epoch 472: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8920 - accuracy: 0.7061 - val_loss: 1.0077 - val_accuracy: 0.6691\n",
      "Epoch 473/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8383 - accuracy: 0.7167\n",
      "Epoch 473: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.8417 - accuracy: 0.7155 - val_loss: 1.0421 - val_accuracy: 0.6463\n",
      "Epoch 474/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8403 - accuracy: 0.7166\n",
      "Epoch 474: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8419 - accuracy: 0.7164 - val_loss: 1.0035 - val_accuracy: 0.6714\n",
      "Epoch 475/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8261 - accuracy: 0.7221\n",
      "Epoch 475: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8248 - accuracy: 0.7228 - val_loss: 0.9955 - val_accuracy: 0.6691\n",
      "Epoch 476/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8319 - accuracy: 0.7231\n",
      "Epoch 476: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8319 - accuracy: 0.7234 - val_loss: 1.0578 - val_accuracy: 0.6508\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8025 - accuracy: 0.7293\n",
      "Epoch 477: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8025 - accuracy: 0.7293 - val_loss: 0.9963 - val_accuracy: 0.6875\n",
      "Epoch 478/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7645 - accuracy: 0.7376\n",
      "Epoch 478: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7627 - accuracy: 0.7377 - val_loss: 0.9747 - val_accuracy: 0.7069\n",
      "Epoch 479/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7538 - accuracy: 0.7433\n",
      "Epoch 479: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7543 - accuracy: 0.7429 - val_loss: 0.9902 - val_accuracy: 0.6812\n",
      "Epoch 480/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7621 - accuracy: 0.7438\n",
      "Epoch 480: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7606 - accuracy: 0.7443 - val_loss: 1.0207 - val_accuracy: 0.6800\n",
      "Epoch 481/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7501 - accuracy: 0.7512\n",
      "Epoch 481: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7491 - accuracy: 0.7515 - val_loss: 0.9736 - val_accuracy: 0.6920\n",
      "Epoch 482/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7231 - accuracy: 0.7552\n",
      "Epoch 482: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7222 - accuracy: 0.7556 - val_loss: 0.9852 - val_accuracy: 0.6898\n",
      "Epoch 483/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7163 - accuracy: 0.7582\n",
      "Epoch 483: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7189 - accuracy: 0.7572 - val_loss: 0.9695 - val_accuracy: 0.6909\n",
      "Epoch 484/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9057 - accuracy: 0.7018\n",
      "Epoch 484: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.9050 - accuracy: 0.7021 - val_loss: 0.9743 - val_accuracy: 0.6726\n",
      "Epoch 485/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8251 - accuracy: 0.7274\n",
      "Epoch 485: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.8256 - accuracy: 0.7276 - val_loss: 1.0286 - val_accuracy: 0.6709\n",
      "Epoch 486/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8648 - accuracy: 0.7073\n",
      "Epoch 486: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8638 - accuracy: 0.7078 - val_loss: 1.0592 - val_accuracy: 0.6726\n",
      "Epoch 487/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7958 - accuracy: 0.7334\n",
      "Epoch 487: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7970 - accuracy: 0.7331 - val_loss: 0.9709 - val_accuracy: 0.6972\n",
      "Epoch 488/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7898 - accuracy: 0.7342\n",
      "Epoch 488: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7893 - accuracy: 0.7343 - val_loss: 1.0015 - val_accuracy: 0.6777\n",
      "Epoch 489/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7446 - accuracy: 0.7491\n",
      "Epoch 489: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7428 - accuracy: 0.7503 - val_loss: 0.9529 - val_accuracy: 0.6943\n",
      "Epoch 490/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6962 - accuracy: 0.7606\n",
      "Epoch 490: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.6972 - accuracy: 0.7599 - val_loss: 0.9548 - val_accuracy: 0.6892\n",
      "Epoch 491/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6998 - accuracy: 0.7690\n",
      "Epoch 491: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7008 - accuracy: 0.7692 - val_loss: 1.0698 - val_accuracy: 0.6920\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.7520\n",
      "Epoch 492: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7443 - accuracy: 0.7520 - val_loss: 0.9514 - val_accuracy: 0.6972\n",
      "Epoch 493/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7480 - accuracy: 0.7499\n",
      "Epoch 493: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7502 - accuracy: 0.7489 - val_loss: 0.9975 - val_accuracy: 0.6846\n",
      "Epoch 494/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8276 - accuracy: 0.7274\n",
      "Epoch 494: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.8249 - accuracy: 0.7278 - val_loss: 1.0604 - val_accuracy: 0.6829\n",
      "Epoch 495/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7593 - accuracy: 0.7454\n",
      "Epoch 495: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.7593 - accuracy: 0.7456 - val_loss: 1.0024 - val_accuracy: 0.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7964 - accuracy: 0.7376\n",
      "Epoch 496: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7981 - accuracy: 0.7367 - val_loss: 1.0058 - val_accuracy: 0.6943\n",
      "Epoch 497/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7385 - accuracy: 0.7509\n",
      "Epoch 497: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.7383 - accuracy: 0.7512 - val_loss: 1.0130 - val_accuracy: 0.6663\n",
      "Epoch 498/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7490 - accuracy: 0.7448\n",
      "Epoch 498: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7475 - accuracy: 0.7453 - val_loss: 0.9546 - val_accuracy: 0.6978\n",
      "Epoch 499/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7410 - accuracy: 0.7510\n",
      "Epoch 499: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.7402 - accuracy: 0.7518 - val_loss: 1.0475 - val_accuracy: 0.6903\n",
      "Epoch 500/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6810 - accuracy: 0.7740\n",
      "Epoch 500: val_loss did not improve from 0.93422\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.6808 - accuracy: 0.7744 - val_loss: 1.0329 - val_accuracy: 0.6754\n",
      "Training completed in time:  0:10:25.205274\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 500\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "922fb867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 0s 3ms/step\n",
      "test metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7227    0.8154    0.7663       195\n",
      "           1     0.9138    0.5824    0.7114        91\n",
      "           2     0.4573    0.7317    0.5629       205\n",
      "           3     0.6330    0.6538    0.6432       182\n",
      "           4     0.6612    0.5990    0.6286       202\n",
      "           5     0.8793    0.7083    0.7846       216\n",
      "           6     0.8214    0.7931    0.8070        87\n",
      "           7     0.9281    0.6898    0.7914       187\n",
      "           8     0.9638    0.6683    0.7893       199\n",
      "           9     0.4000    0.5137    0.4498       183\n",
      "\n",
      "    accuracy                         0.6754      1747\n",
      "   macro avg     0.7381    0.6756    0.6934      1747\n",
      "weighted avg     0.7250    0.6754    0.6873      1747\n",
      "\n",
      "Accuracy: 67.54%\n",
      "Precision: 72.50%\n",
      "Recall: 67.54%\n",
      "F1-score: 68.73%\n",
      "-----------------------\n",
      "train metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8899    0.8932    0.8915       805\n",
      "           1     0.9919    0.7249    0.8376       338\n",
      "           2     0.5457    0.8943    0.6778       795\n",
      "           3     0.7905    0.7518    0.7707       818\n",
      "           4     0.7831    0.7419    0.7619       798\n",
      "           5     0.9162    0.8508    0.8823       784\n",
      "           6     0.8889    0.8362    0.8618       287\n",
      "           7     0.9940    0.8204    0.8989       813\n",
      "           8     0.9964    0.7534    0.8580       730\n",
      "           9     0.6170    0.6585    0.6371       817\n",
      "\n",
      "    accuracy                         0.7937      6985\n",
      "   macro avg     0.8413    0.7925    0.8078      6985\n",
      "weighted avg     0.8260    0.7937    0.8010      6985\n",
      "\n",
      "Accuracy: 79.37%\n",
      "Precision: 82.60%\n",
      "Recall: 79.37%\n",
      "F1-score: 80.10%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix \n",
    " \n",
    "# Train set \n",
    "y_train_pred = model.predict(X_train) \n",
    "y_train_pred = np.argmax(y_train_pred, axis=1) \n",
    "y_train_true = np.argmax(y_train, axis=1) \n",
    " \n",
    "# Test set \n",
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.argmax(y_pred, axis=1) \n",
    "y_true = np.argmax(y_test, axis=1) \n",
    " \n",
    "# # Confusion Metrix \n",
    "# cm = confusion_matrix(y_true, y_pred) \n",
    "# cm_train = confusion_matrix(y_train_true, y_train_pred)\n",
    "\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "print('test metrics: ')\n",
    "print(report)\n",
    "\n",
    "accuracy = float(re.findall(r'accuracy\\s+([\\d.]+)', report)[0])\n",
    "precision = float(re.findall(r'weighted avg\\s+([\\d.]+)', report)[0])\n",
    "recall = float(re.findall(r'weighted avg\\s+([\\d.]+)\\s+([\\d.]+)', report)[0][1])\n",
    "f1_score = float(re.findall(r'weighted avg\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)', report)[0][2])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1-score: {f1_score:.2%}\")\n",
    "\n",
    "report = classification_report(y_train_true, y_train_pred, digits=4)\n",
    "print('-----------------------')\n",
    "print('train metrics: ')\n",
    "print(report)\n",
    "\n",
    "accuracy_train = float(re.findall(r'accuracy\\s+([\\d.]+)', report)[0])\n",
    "precision_train = float(re.findall(r'weighted avg\\s+([\\d.]+)', report)[0])\n",
    "recall_train = float(re.findall(r'weighted avg\\s+([\\d.]+)\\s+([\\d.]+)', report)[0][1])\n",
    "f1_score_train = float(re.findall(r'weighted avg\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)', report)[0][2])\n",
    "\n",
    "print(f\"Accuracy: {accuracy_train:.2%}\")\n",
    "print(f\"Precision: {precision_train:.2%}\")\n",
    "print(f\"Recall: {recall_train:.2%}\")\n",
    "print(f\"F1-score: {f1_score_train:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea3f00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214081525802612\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93885004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-466.17957   ,    1.0950246 ,  -34.01389   ,   35.33935   ,\n",
       "        -14.88148   ,  -19.12843   ,   -0.581684  ,  -16.130579  ,\n",
       "        -21.339075  ,    7.673634  ,  -29.16449   ,  -18.950253  ,\n",
       "         -2.9579995 ,   -8.162329  ,  -15.153101  ,   -6.604805  ,\n",
       "         -7.5685983 ,    9.340646  ,   14.4331    ,   21.934181  ,\n",
       "         20.861397  ,    1.3340122 ,  -19.228804  ,   -4.630231  ,\n",
       "         -1.0564744 ,    3.215267  ,   -6.984281  ,  -16.414577  ,\n",
       "        -10.0286455 ,   13.009954  ,    0.5334608 ,  -23.843391  ,\n",
       "        -15.267321  ,    9.245734  ,   10.367627  ,   -0.58320105,\n",
       "         -1.2624055 ,   17.700016  ,   13.847463  ,   -5.1862826 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59db51eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0923 - accuracy: 0.6525\n",
      "Epoch 2/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1596 - accuracy: 0.6400\n",
      "Epoch 3/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0836 - accuracy: 0.6382\n",
      "Epoch 4/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1313 - accuracy: 0.6119\n",
      "Epoch 5/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0802 - accuracy: 0.6485\n",
      "Epoch 6/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0203 - accuracy: 0.6571\n",
      "Epoch 7/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0006 - accuracy: 0.6783\n",
      "Epoch 8/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0395 - accuracy: 0.6606\n",
      "Epoch 9/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9597 - accuracy: 0.6949\n",
      "Epoch 10/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0041 - accuracy: 0.6617\n",
      "Epoch 11/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9906 - accuracy: 0.6817\n",
      "Epoch 12/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9821 - accuracy: 0.6691\n",
      "Epoch 13/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0359 - accuracy: 0.6571\n",
      "Epoch 14/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9664 - accuracy: 0.6760\n",
      "Epoch 15/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9316 - accuracy: 0.6869\n",
      "Epoch 16/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9372 - accuracy: 0.6846\n",
      "Epoch 17/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9444 - accuracy: 0.6915\n",
      "Epoch 18/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9141 - accuracy: 0.6846\n",
      "Epoch 19/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.7172\n",
      "Epoch 20/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8834 - accuracy: 0.7023\n",
      "Epoch 21/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8989 - accuracy: 0.7086\n",
      "Epoch 22/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9002 - accuracy: 0.7115\n",
      "Epoch 23/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8722 - accuracy: 0.7195\n",
      "Epoch 24/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9389 - accuracy: 0.6806\n",
      "Epoch 25/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9252 - accuracy: 0.6920\n",
      "Epoch 26/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9045 - accuracy: 0.7046\n",
      "Epoch 27/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9164 - accuracy: 0.7041\n",
      "Epoch 28/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9119 - accuracy: 0.7069\n",
      "Epoch 29/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9265 - accuracy: 0.7041\n",
      "Epoch 30/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8607 - accuracy: 0.7109\n",
      "Epoch 31/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9004 - accuracy: 0.7247\n",
      "Epoch 32/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8326 - accuracy: 0.7155\n",
      "Epoch 33/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.7109\n",
      "Epoch 34/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8693 - accuracy: 0.7081\n",
      "Epoch 35/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8427 - accuracy: 0.7338\n",
      "Epoch 36/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.7167\n",
      "Epoch 37/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8649 - accuracy: 0.7195\n",
      "Epoch 38/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9006 - accuracy: 0.6943\n",
      "Epoch 39/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8617 - accuracy: 0.7127\n",
      "Epoch 40/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8615 - accuracy: 0.7121\n",
      "Epoch 41/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.7058\n",
      "Epoch 42/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.7275\n",
      "Epoch 43/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8248 - accuracy: 0.7230\n",
      "Epoch 44/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8961 - accuracy: 0.6920\n",
      "Epoch 45/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8266 - accuracy: 0.7155\n",
      "Epoch 46/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8721 - accuracy: 0.6972\n",
      "Epoch 47/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8203 - accuracy: 0.7321\n",
      "Epoch 48/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8299 - accuracy: 0.7218\n",
      "Epoch 49/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8110 - accuracy: 0.7189\n",
      "Epoch 50/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8080 - accuracy: 0.7344\n",
      "Epoch 51/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8028 - accuracy: 0.7390\n",
      "Epoch 52/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8391 - accuracy: 0.7241\n",
      "Epoch 53/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8777 - accuracy: 0.7149\n",
      "Epoch 54/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8392 - accuracy: 0.7189\n",
      "Epoch 55/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8379 - accuracy: 0.7241\n",
      "Epoch 56/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8055 - accuracy: 0.7396\n",
      "Epoch 57/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8124 - accuracy: 0.7310\n",
      "Epoch 58/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8338 - accuracy: 0.7247\n",
      "Epoch 59/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7862 - accuracy: 0.7424\n",
      "Epoch 60/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8610 - accuracy: 0.7230\n",
      "Epoch 61/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8471 - accuracy: 0.7315\n",
      "Epoch 62/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.7854 - accuracy: 0.7338\n",
      "Epoch 63/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8081 - accuracy: 0.7390\n",
      "Epoch 64/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8413 - accuracy: 0.7275\n",
      "Epoch 65/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.7424\n",
      "Epoch 66/70\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.7436\n",
      "Epoch 67/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.7350\n",
      "Epoch 68/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8113 - accuracy: 0.7361\n",
      "Epoch 69/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.8065 - accuracy: 0.7338\n",
      "Epoch 70/70\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.7962 - accuracy: 0.7361\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_test, y_test, epochs=70, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07ed41e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f7afd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4228b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6af126b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.9926 - accuracy: 0.6825\n",
      "Epoch 2/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.9300 - accuracy: 0.6929\n",
      "Epoch 3/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8830 - accuracy: 0.7102\n",
      "Epoch 4/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.7058\n",
      "Epoch 5/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8885 - accuracy: 0.7045\n",
      "Epoch 6/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8742 - accuracy: 0.7107\n",
      "Epoch 7/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8862 - accuracy: 0.7052\n",
      "Epoch 8/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8698 - accuracy: 0.7161\n",
      "Epoch 9/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8666 - accuracy: 0.7195\n",
      "Epoch 10/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8626 - accuracy: 0.7200\n",
      "Epoch 11/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8653 - accuracy: 0.7131\n",
      "Epoch 12/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8470 - accuracy: 0.7227\n",
      "Epoch 13/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8643 - accuracy: 0.7195\n",
      "Epoch 14/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8416 - accuracy: 0.7210\n",
      "Epoch 15/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8347 - accuracy: 0.7270\n",
      "Epoch 16/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8496 - accuracy: 0.7230\n",
      "Epoch 17/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8414 - accuracy: 0.7180\n",
      "Epoch 18/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8357 - accuracy: 0.7211\n",
      "Epoch 19/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8470 - accuracy: 0.7138\n",
      "Epoch 20/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8379 - accuracy: 0.7201\n",
      "Epoch 21/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8404 - accuracy: 0.7227\n",
      "Epoch 22/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8351 - accuracy: 0.7258\n",
      "Epoch 23/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8463 - accuracy: 0.7221\n",
      "Epoch 24/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8250 - accuracy: 0.7277\n",
      "Epoch 25/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8447 - accuracy: 0.7167\n",
      "Epoch 26/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8353 - accuracy: 0.7225\n",
      "Epoch 27/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8476 - accuracy: 0.7194\n",
      "Epoch 28/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8720 - accuracy: 0.7205\n",
      "Epoch 29/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8532 - accuracy: 0.7173\n",
      "Epoch 30/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8330 - accuracy: 0.7210\n",
      "Epoch 31/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8334 - accuracy: 0.7247\n",
      "Epoch 32/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8120 - accuracy: 0.7260\n",
      "Epoch 33/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8315 - accuracy: 0.7324\n",
      "Epoch 34/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8379 - accuracy: 0.7260\n",
      "Epoch 35/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8387 - accuracy: 0.7319\n",
      "Epoch 36/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8551 - accuracy: 0.7264\n",
      "Epoch 37/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8302 - accuracy: 0.7304\n",
      "Epoch 38/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8243 - accuracy: 0.7327\n",
      "Epoch 39/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8193 - accuracy: 0.7296\n",
      "Epoch 40/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8140 - accuracy: 0.7304\n",
      "Epoch 41/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8538 - accuracy: 0.7253\n",
      "Epoch 42/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8169 - accuracy: 0.7296\n",
      "Epoch 43/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8340 - accuracy: 0.7276\n",
      "Epoch 44/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8158 - accuracy: 0.7303\n",
      "Epoch 45/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8056 - accuracy: 0.7383\n",
      "Epoch 46/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8244 - accuracy: 0.7246\n",
      "Epoch 47/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8124 - accuracy: 0.7274\n",
      "Epoch 48/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8169 - accuracy: 0.7304\n",
      "Epoch 49/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8077 - accuracy: 0.7394\n",
      "Epoch 50/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8121 - accuracy: 0.7356\n",
      "Epoch 51/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8183 - accuracy: 0.7336\n",
      "Epoch 52/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8378 - accuracy: 0.7213\n",
      "Epoch 53/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8383 - accuracy: 0.7241\n",
      "Epoch 54/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.7968 - accuracy: 0.7370\n",
      "Epoch 55/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8187 - accuracy: 0.7273\n",
      "Epoch 56/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8014 - accuracy: 0.7393\n",
      "Epoch 57/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8276 - accuracy: 0.7267\n",
      "Epoch 58/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.7313\n",
      "Epoch 59/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8201 - accuracy: 0.7294\n",
      "Epoch 60/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8088 - accuracy: 0.7397\n",
      "Epoch 61/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8144 - accuracy: 0.7356\n",
      "Epoch 62/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8120 - accuracy: 0.7331\n",
      "Epoch 63/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8229 - accuracy: 0.7291\n",
      "Epoch 64/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8302 - accuracy: 0.7234\n",
      "Epoch 65/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8071 - accuracy: 0.7357\n",
      "Epoch 66/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.7996 - accuracy: 0.7382\n",
      "Epoch 67/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8079 - accuracy: 0.7361\n",
      "Epoch 68/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8444 - accuracy: 0.7208\n",
      "Epoch 69/70\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.7995 - accuracy: 0.7331\n",
      "Epoch 70/70\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8036 - accuracy: 0.7330\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, y_train, epochs=70, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fed2b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d5bbb73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9002a37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18298ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8704366683959961\n",
      "Testing Accuracy:  0.8179736733436584\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba86d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffee5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70e8b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 81.7974%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60ec5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.7953 - accuracy: 0.7424\n",
      "Epoch 1: val_loss improved from inf to 0.57982, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.7896 - accuracy: 0.7427 - val_loss: 0.5798 - val_accuracy: 0.8208\n",
      "Epoch 2/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8184 - accuracy: 0.7333\n",
      "Epoch 2: val_loss improved from 0.57982 to 0.56807, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8179 - accuracy: 0.7334 - val_loss: 0.5681 - val_accuracy: 0.8266\n",
      "Epoch 3/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8124 - accuracy: 0.7363\n",
      "Epoch 3: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8106 - accuracy: 0.7374 - val_loss: 0.5890 - val_accuracy: 0.8226\n",
      "Epoch 4/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.7321\n",
      "Epoch 4: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8021 - accuracy: 0.7323 - val_loss: 0.5769 - val_accuracy: 0.8231\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7898 - accuracy: 0.7402\n",
      "Epoch 5: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7898 - accuracy: 0.7402 - val_loss: 0.5901 - val_accuracy: 0.8128\n",
      "Epoch 6/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7909 - accuracy: 0.7398\n",
      "Epoch 6: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.7914 - accuracy: 0.7399 - val_loss: 0.5822 - val_accuracy: 0.8163\n",
      "Epoch 7/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7937 - accuracy: 0.7375\n",
      "Epoch 7: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.7974 - accuracy: 0.7353 - val_loss: 0.6001 - val_accuracy: 0.8288\n",
      "Epoch 8/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8240 - accuracy: 0.7304\n",
      "Epoch 8: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8236 - accuracy: 0.7304 - val_loss: 0.5875 - val_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.7749 - accuracy: 0.7482\n",
      "Epoch 9: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7752 - accuracy: 0.7482 - val_loss: 0.6142 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7973 - accuracy: 0.7306\n",
      "Epoch 10: val_loss did not improve from 0.56807\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7973 - accuracy: 0.7306 - val_loss: 0.5744 - val_accuracy: 0.8208\n",
      "Epoch 11/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.7878 - accuracy: 0.7401\n",
      "Epoch 11: val_loss improved from 0.56807 to 0.56622, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7963 - accuracy: 0.7384 - val_loss: 0.5662 - val_accuracy: 0.8266\n",
      "Epoch 12/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7980 - accuracy: 0.7392\n",
      "Epoch 12: val_loss did not improve from 0.56622\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8006 - accuracy: 0.7382 - val_loss: 0.5794 - val_accuracy: 0.8226\n",
      "Epoch 13/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7900 - accuracy: 0.7403\n",
      "Epoch 13: val_loss did not improve from 0.56622\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7897 - accuracy: 0.7402 - val_loss: 0.5933 - val_accuracy: 0.8185\n",
      "Epoch 14/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8033 - accuracy: 0.7403\n",
      "Epoch 14: val_loss did not improve from 0.56622\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8034 - accuracy: 0.7406 - val_loss: 0.5802 - val_accuracy: 0.8208\n",
      "Epoch 15/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7986 - accuracy: 0.7469\n",
      "Epoch 15: val_loss improved from 0.56622 to 0.56403, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7934 - accuracy: 0.7473 - val_loss: 0.5640 - val_accuracy: 0.8300\n",
      "Epoch 16/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8094 - accuracy: 0.7356\n",
      "Epoch 16: val_loss did not improve from 0.56403\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8070 - accuracy: 0.7361 - val_loss: 0.5904 - val_accuracy: 0.8271\n",
      "Epoch 17/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7984 - accuracy: 0.7355\n",
      "Epoch 17: val_loss improved from 0.56403 to 0.56090, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7995 - accuracy: 0.7347 - val_loss: 0.5609 - val_accuracy: 0.8432\n",
      "Epoch 18/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7852 - accuracy: 0.7386\n",
      "Epoch 18: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7854 - accuracy: 0.7384 - val_loss: 0.5654 - val_accuracy: 0.8317\n",
      "Epoch 19/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8040 - accuracy: 0.7382\n",
      "Epoch 19: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8037 - accuracy: 0.7383 - val_loss: 0.5668 - val_accuracy: 0.8277\n",
      "Epoch 20/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7825 - accuracy: 0.7429\n",
      "Epoch 20: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7817 - accuracy: 0.7433 - val_loss: 0.5764 - val_accuracy: 0.8283\n",
      "Epoch 21/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.7356\n",
      "Epoch 21: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7952 - accuracy: 0.7351 - val_loss: 0.5775 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7914 - accuracy: 0.7356\n",
      "Epoch 22: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7919 - accuracy: 0.7356 - val_loss: 0.5794 - val_accuracy: 0.8294\n",
      "Epoch 23/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.7377\n",
      "Epoch 23: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7810 - accuracy: 0.7376 - val_loss: 0.5780 - val_accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.7411\n",
      "Epoch 24: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7924 - accuracy: 0.7420 - val_loss: 0.5659 - val_accuracy: 0.8346\n",
      "Epoch 25/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8117 - accuracy: 0.7356\n",
      "Epoch 25: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8123 - accuracy: 0.7351 - val_loss: 0.6039 - val_accuracy: 0.8163\n",
      "Epoch 26/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7850 - accuracy: 0.7386\n",
      "Epoch 26: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7845 - accuracy: 0.7390 - val_loss: 0.5745 - val_accuracy: 0.8277\n",
      "Epoch 27/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8042 - accuracy: 0.7367\n",
      "Epoch 27: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8031 - accuracy: 0.7373 - val_loss: 0.5878 - val_accuracy: 0.8203\n",
      "Epoch 28/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8002 - accuracy: 0.7406\n",
      "Epoch 28: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7992 - accuracy: 0.7412 - val_loss: 0.5702 - val_accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8125 - accuracy: 0.7317\n",
      "Epoch 29: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8102 - accuracy: 0.7317 - val_loss: 0.5886 - val_accuracy: 0.8220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8012 - accuracy: 0.7373\n",
      "Epoch 30: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8012 - accuracy: 0.7373 - val_loss: 0.5937 - val_accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8026 - accuracy: 0.7397\n",
      "Epoch 31: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8026 - accuracy: 0.7397 - val_loss: 0.5829 - val_accuracy: 0.8145\n",
      "Epoch 32/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8009 - accuracy: 0.7345\n",
      "Epoch 32: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8005 - accuracy: 0.7344 - val_loss: 0.5688 - val_accuracy: 0.8266\n",
      "Epoch 33/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7520 - accuracy: 0.7471\n",
      "Epoch 33: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7540 - accuracy: 0.7463 - val_loss: 0.5685 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7774 - accuracy: 0.7448\n",
      "Epoch 34: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7752 - accuracy: 0.7462 - val_loss: 0.5637 - val_accuracy: 0.8288\n",
      "Epoch 35/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.7852 - accuracy: 0.7422\n",
      "Epoch 35: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7796 - accuracy: 0.7440 - val_loss: 0.5755 - val_accuracy: 0.8157\n",
      "Epoch 36/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7681 - accuracy: 0.7446\n",
      "Epoch 36: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7716 - accuracy: 0.7460 - val_loss: 0.5779 - val_accuracy: 0.8243\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.7443\n",
      "Epoch 37: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7708 - accuracy: 0.7443 - val_loss: 0.5769 - val_accuracy: 0.8237\n",
      "Epoch 38/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.7669 - accuracy: 0.7440\n",
      "Epoch 38: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7658 - accuracy: 0.7437 - val_loss: 0.6003 - val_accuracy: 0.8197\n",
      "Epoch 39/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.7932 - accuracy: 0.7434\n",
      "Epoch 39: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7895 - accuracy: 0.7437 - val_loss: 0.5959 - val_accuracy: 0.8157\n",
      "Epoch 40/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8134 - accuracy: 0.7384\n",
      "Epoch 40: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8133 - accuracy: 0.7386 - val_loss: 0.5828 - val_accuracy: 0.8323\n",
      "Epoch 41/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8038 - accuracy: 0.7337\n",
      "Epoch 41: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8032 - accuracy: 0.7340 - val_loss: 0.5912 - val_accuracy: 0.8243\n",
      "Epoch 42/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7866 - accuracy: 0.7380\n",
      "Epoch 42: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7826 - accuracy: 0.7399 - val_loss: 0.5784 - val_accuracy: 0.8231\n",
      "Epoch 43/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.7877 - accuracy: 0.7433\n",
      "Epoch 43: val_loss did not improve from 0.56090\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7846 - accuracy: 0.7443 - val_loss: 0.5893 - val_accuracy: 0.8151\n",
      "Epoch 44/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7988 - accuracy: 0.7420\n",
      "Epoch 44: val_loss improved from 0.56090 to 0.56030, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7968 - accuracy: 0.7427 - val_loss: 0.5603 - val_accuracy: 0.8329\n",
      "Epoch 45/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7868 - accuracy: 0.7449\n",
      "Epoch 45: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7871 - accuracy: 0.7442 - val_loss: 0.5646 - val_accuracy: 0.8277\n",
      "Epoch 46/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.7936 - accuracy: 0.7386\n",
      "Epoch 46: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7931 - accuracy: 0.7394 - val_loss: 0.5643 - val_accuracy: 0.8248\n",
      "Epoch 47/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7971 - accuracy: 0.7343\n",
      "Epoch 47: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7979 - accuracy: 0.7337 - val_loss: 0.5759 - val_accuracy: 0.8203\n",
      "Epoch 48/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8179 - accuracy: 0.7279\n",
      "Epoch 48: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8143 - accuracy: 0.7296 - val_loss: 0.5663 - val_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7914 - accuracy: 0.7337\n",
      "Epoch 49: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7968 - accuracy: 0.7329 - val_loss: 0.5641 - val_accuracy: 0.8277\n",
      "Epoch 50/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8001 - accuracy: 0.7362\n",
      "Epoch 50: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.8000 - accuracy: 0.7357 - val_loss: 0.5623 - val_accuracy: 0.8288\n",
      "Epoch 51/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7808 - accuracy: 0.7403\n",
      "Epoch 51: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7810 - accuracy: 0.7406 - val_loss: 0.5769 - val_accuracy: 0.8197\n",
      "Epoch 52/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7813 - accuracy: 0.7436\n",
      "Epoch 52: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7835 - accuracy: 0.7426 - val_loss: 0.5697 - val_accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.7400\n",
      "Epoch 53: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.7793 - accuracy: 0.7413 - val_loss: 0.5624 - val_accuracy: 0.8346\n",
      "Epoch 54/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7573 - accuracy: 0.7517\n",
      "Epoch 54: val_loss did not improve from 0.56030\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7558 - accuracy: 0.7516 - val_loss: 0.5647 - val_accuracy: 0.8311\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7794 - accuracy: 0.7442\n",
      "Epoch 55: val_loss improved from 0.56030 to 0.55995, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7794 - accuracy: 0.7442 - val_loss: 0.5600 - val_accuracy: 0.8237\n",
      "Epoch 56/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7874 - accuracy: 0.7391\n",
      "Epoch 56: val_loss improved from 0.55995 to 0.54476, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7884 - accuracy: 0.7389 - val_loss: 0.5448 - val_accuracy: 0.8288\n",
      "Epoch 57/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7763 - accuracy: 0.7413\n",
      "Epoch 57: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7725 - accuracy: 0.7427 - val_loss: 0.5787 - val_accuracy: 0.8134\n",
      "Epoch 58/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7858 - accuracy: 0.7359\n",
      "Epoch 58: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7913 - accuracy: 0.7353 - val_loss: 0.5742 - val_accuracy: 0.8151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7885 - accuracy: 0.7428\n",
      "Epoch 59: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.7429 - val_loss: 0.5885 - val_accuracy: 0.8197\n",
      "Epoch 60/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7920 - accuracy: 0.7350\n",
      "Epoch 60: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7914 - accuracy: 0.7354 - val_loss: 0.5758 - val_accuracy: 0.8180\n",
      "Epoch 61/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7905 - accuracy: 0.7360\n",
      "Epoch 61: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7910 - accuracy: 0.7359 - val_loss: 0.5867 - val_accuracy: 0.8180\n",
      "Epoch 62/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7762 - accuracy: 0.7450\n",
      "Epoch 62: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7745 - accuracy: 0.7457 - val_loss: 0.5882 - val_accuracy: 0.8191\n",
      "Epoch 63/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7867 - accuracy: 0.7425\n",
      "Epoch 63: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7877 - accuracy: 0.7417 - val_loss: 0.5552 - val_accuracy: 0.8271\n",
      "Epoch 64/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7760 - accuracy: 0.7445\n",
      "Epoch 64: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7767 - accuracy: 0.7446 - val_loss: 0.5717 - val_accuracy: 0.8197\n",
      "Epoch 65/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7754 - accuracy: 0.7448\n",
      "Epoch 65: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7735 - accuracy: 0.7453 - val_loss: 0.5616 - val_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7840 - accuracy: 0.7459\n",
      "Epoch 66: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7842 - accuracy: 0.7456 - val_loss: 0.5648 - val_accuracy: 0.8271\n",
      "Epoch 67/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7449\n",
      "Epoch 67: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7713 - accuracy: 0.7439 - val_loss: 0.5510 - val_accuracy: 0.8288\n",
      "Epoch 68/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8025 - accuracy: 0.7383\n",
      "Epoch 68: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7971 - accuracy: 0.7396 - val_loss: 0.5617 - val_accuracy: 0.8248\n",
      "Epoch 69/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7502 - accuracy: 0.7514\n",
      "Epoch 69: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7496 - accuracy: 0.7518 - val_loss: 0.5633 - val_accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7748 - accuracy: 0.7420\n",
      "Epoch 70: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7743 - accuracy: 0.7422 - val_loss: 0.5701 - val_accuracy: 0.8311\n",
      "Epoch 71/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7872 - accuracy: 0.7425\n",
      "Epoch 71: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7855 - accuracy: 0.7426 - val_loss: 0.5780 - val_accuracy: 0.8191\n",
      "Epoch 72/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7616 - accuracy: 0.7478\n",
      "Epoch 72: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7605 - accuracy: 0.7480 - val_loss: 0.5727 - val_accuracy: 0.8180\n",
      "Epoch 73/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7762 - accuracy: 0.7466\n",
      "Epoch 73: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7777 - accuracy: 0.7460 - val_loss: 0.5814 - val_accuracy: 0.8237\n",
      "Epoch 74/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7857 - accuracy: 0.7406\n",
      "Epoch 74: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7869 - accuracy: 0.7402 - val_loss: 0.5649 - val_accuracy: 0.8260\n",
      "Epoch 75/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7630 - accuracy: 0.7480\n",
      "Epoch 75: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7626 - accuracy: 0.7482 - val_loss: 0.5586 - val_accuracy: 0.8243\n",
      "Epoch 76/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8045 - accuracy: 0.7377\n",
      "Epoch 76: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8048 - accuracy: 0.7376 - val_loss: 0.5550 - val_accuracy: 0.8329\n",
      "Epoch 77/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7730 - accuracy: 0.7494\n",
      "Epoch 77: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7722 - accuracy: 0.7497 - val_loss: 0.5705 - val_accuracy: 0.8208\n",
      "Epoch 78/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7727 - accuracy: 0.7415\n",
      "Epoch 78: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7725 - accuracy: 0.7412 - val_loss: 0.5488 - val_accuracy: 0.8329\n",
      "Epoch 79/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8180 - accuracy: 0.7346\n",
      "Epoch 79: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.8176 - accuracy: 0.7346 - val_loss: 0.5707 - val_accuracy: 0.8277\n",
      "Epoch 80/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7877 - accuracy: 0.7423\n",
      "Epoch 80: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7865 - accuracy: 0.7426 - val_loss: 0.6059 - val_accuracy: 0.8203\n",
      "Epoch 81/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.7471\n",
      "Epoch 81: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7898 - accuracy: 0.7475 - val_loss: 0.5589 - val_accuracy: 0.8294\n",
      "Epoch 82/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7771 - accuracy: 0.7467\n",
      "Epoch 82: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7765 - accuracy: 0.7469 - val_loss: 0.5669 - val_accuracy: 0.8231\n",
      "Epoch 83/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7985 - accuracy: 0.7412\n",
      "Epoch 83: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7985 - accuracy: 0.7414 - val_loss: 0.5604 - val_accuracy: 0.8351\n",
      "Epoch 84/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.7898 - accuracy: 0.7510\n",
      "Epoch 84: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7906 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.8346\n",
      "Epoch 85/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.7615 - accuracy: 0.7484\n",
      "Epoch 85: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7608 - accuracy: 0.7487 - val_loss: 0.5522 - val_accuracy: 0.8294\n",
      "Epoch 86/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7699 - accuracy: 0.7432\n",
      "Epoch 86: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7690 - accuracy: 0.7433 - val_loss: 0.5753 - val_accuracy: 0.8220\n",
      "Epoch 87/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.7471\n",
      "Epoch 87: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7734 - accuracy: 0.7459 - val_loss: 0.5550 - val_accuracy: 0.8277\n",
      "Epoch 88/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7455\n",
      "Epoch 88: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7686 - accuracy: 0.7457 - val_loss: 0.5654 - val_accuracy: 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.7606 - accuracy: 0.7485\n",
      "Epoch 89: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7624 - accuracy: 0.7480 - val_loss: 0.5670 - val_accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7920 - accuracy: 0.7460\n",
      "Epoch 90: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7920 - accuracy: 0.7460 - val_loss: 0.5789 - val_accuracy: 0.8266\n",
      "Epoch 91/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7699 - accuracy: 0.7466\n",
      "Epoch 91: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7694 - accuracy: 0.7463 - val_loss: 0.5718 - val_accuracy: 0.8203\n",
      "Epoch 92/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.7795 - accuracy: 0.7414\n",
      "Epoch 92: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7805 - accuracy: 0.7407 - val_loss: 0.5753 - val_accuracy: 0.8260\n",
      "Epoch 93/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7503 - accuracy: 0.7445\n",
      "Epoch 93: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7518 - accuracy: 0.7439 - val_loss: 0.5474 - val_accuracy: 0.8392\n",
      "Epoch 94/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7661 - accuracy: 0.7525\n",
      "Epoch 94: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7659 - accuracy: 0.7520 - val_loss: 0.5632 - val_accuracy: 0.8340\n",
      "Epoch 95/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.7856 - accuracy: 0.7458\n",
      "Epoch 95: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7841 - accuracy: 0.7459 - val_loss: 0.5603 - val_accuracy: 0.8351\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.7486\n",
      "Epoch 96: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7726 - accuracy: 0.7486 - val_loss: 0.5945 - val_accuracy: 0.8185\n",
      "Epoch 97/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.7831 - accuracy: 0.7413\n",
      "Epoch 97: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7839 - accuracy: 0.7410 - val_loss: 0.5607 - val_accuracy: 0.8351\n",
      "Epoch 98/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7684 - accuracy: 0.7465\n",
      "Epoch 98: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7662 - accuracy: 0.7467 - val_loss: 0.5524 - val_accuracy: 0.8334\n",
      "Epoch 99/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.7682 - accuracy: 0.7458\n",
      "Epoch 99: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7673 - accuracy: 0.7462 - val_loss: 0.5744 - val_accuracy: 0.8214\n",
      "Epoch 100/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.7857 - accuracy: 0.7484\n",
      "Epoch 100: val_loss did not improve from 0.54476\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.7834 - accuracy: 0.7480 - val_loss: 0.5614 - val_accuracy: 0.8306\n",
      "Training completed in time:  0:02:01.193902\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a507f84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8755905628204346\n",
      "Testing Accuracy:  0.8305667042732239\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84a8bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d723888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a66e569e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Class: Air Conditioner \u001b[39;00m\n\u001b[0;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUrbanSound8K/100263-2-0-3.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mprint_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mprint_prediction\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_prediction\u001b[39m(file_name):\n\u001b[0;32m      2\u001b[0m     prediction_feature \u001b[38;5;241m=\u001b[39m extract_feature(file_name) \n\u001b[1;32m----> 4\u001b[0m     predicted_vector \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(prediction_feature)\n\u001b[0;32m      5\u001b[0m     predicted_class \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform(predicted_vector) \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe predicted class is:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_class[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner \n",
    "\n",
    "filename = 'UrbanSound8K/100263-2-0-3.wav'\n",
    "print_prediction(filename) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
